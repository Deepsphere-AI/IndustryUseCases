{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Step 1 - Import the Required Libraries\n",
    "################################\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import _pickle as cPickle\n",
    "from pathlib import Path\n",
    "import gensim\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\AI\\AUTOMATIC QUESTION GENERATION\\ML\\TRAINING DATA\\pickles\\nb-predictor.pkl\n",
      "C:\\AI\\AUTOMATIC QUESTION GENERATION\\ML\\TRAINING DATA\\pickles\\wordsDf.pkl\n",
      "C:\\AI\\AUTOMATIC QUESTION GENERATION\\ML\\TRAINING DATA\\embeddings\\glove.6B.300d.txt\n",
      "C:\\AI\\AUTOMATIC QUESTION GENERATION\\ML\\TRAINING DATA\\embeddings\\word2vec-glove.6B.300d.txt\n",
      "C:\\AI\\AUTOMATIC QUESTION GENERATION\\ML\\TEST DATA\\MCQ_AI_DATA.txt\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "import os\n",
    "\n",
    "vAR_Config = configparser.ConfigParser(allow_no_value=True)\n",
    "\n",
    "vAR_INI_FILE_PATH = os.getenv('AQG')\n",
    "#print(vAR_INI_FILE_PATH)\n",
    "\n",
    "vAR_Config.read(vAR_INI_FILE_PATH)\n",
    "\n",
    "vAR_Data = vAR_Config.sections()\n",
    "\n",
    "vAR_Pickle_Data1 =vAR_Config['FILE PATH']['PICKLE_DATA_1']\n",
    "vAR_Pickle_Data2 =vAR_Config['FILE PATH']['PICKLE_DATA_2']\n",
    "vAR_Training_Data1 = vAR_Config['FILE PATH']['TRAINING_DATA_MCQ1']\n",
    "vAR_Training_Data2 =vAR_Config['FILE PATH']['TRAINING_DATA_MCQ2']\n",
    "vAR_Test_Data = vAR_Config['FILE PATH']['TEST_DATA_MCQ1']\n",
    "print(vAR_Pickle_Data1)\n",
    "print(vAR_Pickle_Data2)\n",
    "print(vAR_Training_Data1)\n",
    "print(vAR_Training_Data2)\n",
    "print(vAR_Test_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dumpPickle(fileName, content):\n",
    "    pickleFile = open(fileName, 'wb')\n",
    "    cPickle.dump(content, pickleFile, -1)\n",
    "    pickleFile.close()\n",
    "\n",
    "def loadPickle(fileName):    \n",
    "    file = open(fileName, 'rb')\n",
    "    content = cPickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    return content\n",
    "    \n",
    "def pickleExists(fileName):\n",
    "    file = Path(fileName)\n",
    "    \n",
    "    if file.is_file():\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Extract words and generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "################################\n",
    "#Extract answers and the sentence they are in\n",
    "################################\n",
    "def extractAnswers(qas, doc):\n",
    "    answers = []\n",
    "\n",
    "    senStart = 0\n",
    "    senId = 0\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        senLen = len(sentence.text)\n",
    "\n",
    "        for answer in qas:\n",
    "            answerStart = answer['answers'][0]['answer_start']\n",
    "\n",
    "            if (answerStart >= senStart and answerStart < (senStart + senLen)):\n",
    "                answers.append({'sentenceId': senId, 'text': answer['answers'][0]['text']})\n",
    "\n",
    "        senStart += senLen\n",
    "        senId += 1\n",
    "    \n",
    "    return answers\n",
    "################################\n",
    "# Cleaning answers from stopwords\n",
    "################################\n",
    "def tokenIsAnswer(token, sentenceId, answers):\n",
    "    for i in range(len(answers)):\n",
    "        if (answers[i]['sentenceId'] == sentenceId):\n",
    "            if (answers[i]['text'] == token):\n",
    "                return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Fixing named Entities start points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#Save named entities start points\n",
    "################################\n",
    "\n",
    "def getNEStartIndexs(doc):\n",
    "    neStarts = {}\n",
    "    for ne in doc.ents:\n",
    "        neStarts[ne.start] = ne\n",
    "        \n",
    "    return neStarts \n",
    "\n",
    "def getSentenceStartIndexes(doc):\n",
    "    senStarts = []\n",
    "    \n",
    "    for sentence in doc.sents:\n",
    "        senStarts.append(sentence[0].i)\n",
    "    \n",
    "    return senStarts\n",
    "    \n",
    "def getSentenceForWordPosition(wordPos, senStarts):\n",
    "    for i in range(1, len(senStarts)):\n",
    "        if (wordPos < senStarts[i]):\n",
    "            return i - 1\n",
    "        \n",
    "def addWordsForParagrapgh(newWords, text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    neStarts = getNEStartIndexs(doc)\n",
    "    senStarts = getSentenceStartIndexes(doc)\n",
    "    \n",
    "    #index of word in spacy doc text\n",
    "    i = 0\n",
    "    \n",
    "    while (i < len(doc)):\n",
    "        #If the token is a start of a Named Entity, add it and push to index to end of the NE\n",
    "        if (i in neStarts):\n",
    "            word = neStarts[i]\n",
    "            #add word\n",
    "            currentSentence = getSentenceForWordPosition(word.start, senStarts)\n",
    "            wordLen = word.end - word.start\n",
    "            shape = ''\n",
    "            for wordIndex in range(word.start, word.end):\n",
    "                shape += (' ' + doc[wordIndex].shape_)\n",
    "\n",
    "            newWords.append([word.text,\n",
    "                            0,\n",
    "                            0,\n",
    "                            currentSentence,\n",
    "                            wordLen,\n",
    "                            word.label_,\n",
    "                            None,\n",
    "                            None,\n",
    "                            None,\n",
    "                            shape])\n",
    "            i = neStarts[i].end - 1\n",
    "        #If not a NE, add the word if it's not a stopword or a non-alpha (not regular letters)\n",
    "        else:\n",
    "            if (doc[i].is_stop == False and doc[i].is_alpha == True):\n",
    "                word = doc[i]\n",
    "\n",
    "                currentSentence = getSentenceForWordPosition(i, senStarts)\n",
    "                wordLen = 1\n",
    "\n",
    "                newWords.append([word.text,\n",
    "                                0,\n",
    "                                0,\n",
    "                                currentSentence,\n",
    "                                wordLen,\n",
    "                                None,\n",
    "                                word.pos_,\n",
    "                                word.tag_,\n",
    "                                word.dep_,\n",
    "                                word.shape_])\n",
    "        i += 1\n",
    "\n",
    "def oneHotEncodeColumns(df):\n",
    "    columnsToEncode = ['NER', 'POS', \"TAG\", 'DEP']\n",
    "\n",
    "    for column in columnsToEncode:\n",
    "        one_hot = pd.get_dummies(df[column])\n",
    "        one_hot = one_hot.add_prefix(column + '_')\n",
    "\n",
    "        df = df.drop(column, axis = 1)\n",
    "        df = df.join(one_hot)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Predict whether word is keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDf(text):\n",
    "    words = []\n",
    "    addWordsForParagrapgh(words, text)\n",
    "\n",
    "    wordColums = ['text', 'titleId', 'paragrapghId', 'sentenceId','wordCount', 'NER', 'POS', 'TAG', 'DEP','shape']\n",
    "    df = pd.DataFrame(words, columns=wordColums)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDf(df):\n",
    "    #One-hot encoding\n",
    "    wordsDf = oneHotEncodeColumns(df)\n",
    "\n",
    "    #Drop unused columns\n",
    "    columnsToDrop = ['text', 'titleId', 'paragrapghId', 'sentenceId', 'shape']\n",
    "    wordsDf = wordsDf.drop(columnsToDrop, axis = 1)\n",
    "\n",
    "    #Add missing colums \n",
    "    predictorColumns = ['wordCount','NER_CARDINAL','NER_DATE','NER_EVENT','NER_FAC','NER_GPE','NER_LANGUAGE','NER_LAW','NER_LOC','NER_MONEY','NER_NORP','NER_ORDINAL','NER_ORG','NER_PERCENT','NER_PERSON','NER_PRODUCT','NER_QUANTITY','NER_TIME','NER_WORK_OF_ART','POS_ADJ','POS_ADP','POS_ADV','POS_CCONJ','POS_DET','POS_INTJ','POS_NOUN','POS_NUM','POS_PART','POS_PRON','POS_PROPN','POS_PUNCT','POS_SYM','POS_VERB','POS_X','TAG_''','TAG_-LRB-','TAG_.','TAG_ADD','TAG_AFX','TAG_CC','TAG_CD','TAG_DT','TAG_EX','TAG_FW','TAG_IN','TAG_JJ','TAG_JJR','TAG_JJS','TAG_LS','TAG_MD','TAG_NFP','TAG_NN','TAG_NNP','TAG_NNPS','TAG_NNS','TAG_PDT','TAG_POS','TAG_PRP','TAG_PRP$','TAG_RB','TAG_RBR','TAG_RBS','TAG_RP','TAG_SYM','TAG_TO','TAG_UH','TAG_VB','TAG_VBD','TAG_VBG','TAG_VBN','TAG_VBP','TAG_VBZ','TAG_WDT','TAG_WP','TAG_WRB','TAG_XX','DEP_ROOT','DEP_acl','DEP_acomp','DEP_advcl','DEP_advmod','DEP_agent','DEP_amod','DEP_appos','DEP_attr','DEP_aux','DEP_auxpass','DEP_case','DEP_cc','DEP_ccomp','DEP_compound','DEP_conj','DEP_csubj','DEP_csubjpass','DEP_dative','DEP_dep','DEP_det','DEP_dobj','DEP_expl','DEP_intj','DEP_mark','DEP_meta','DEP_neg','DEP_nmod','DEP_npadvmod','DEP_nsubj','DEP_nsubjpass','DEP_nummod','DEP_oprd','DEP_parataxis','DEP_pcomp','DEP_pobj','DEP_poss','DEP_preconj','DEP_predet','DEP_prep','DEP_prt','DEP_punct','DEP_quantmod','DEP_relcl','DEP_xcomp']\n",
    "\n",
    "    for feature in predictorColumns:\n",
    "        if feature not in wordsDf.columns:\n",
    "            wordsDf[feature] = 0\n",
    "    \n",
    "    return wordsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictWords(wordsDf, df):\n",
    "    \n",
    "    predictorPickleName = vAR_Pickle_Data1\n",
    "    predictor = loadPickle(predictorPickleName)\n",
    "    \n",
    "    y_pred = predictor.predict_proba(wordsDf)\n",
    "\n",
    "    labeledAnswers = []\n",
    "    for i in range(len(y_pred)):\n",
    "        labeledAnswers.append({'word': df.iloc[i]['text'], 'prob': y_pred[i][0]})\n",
    "    \n",
    "    return labeledAnswers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Extract Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blankAnswer(firstTokenIndex, lastTokenIndex, sentStart, sentEnd, doc):\n",
    "    leftPartStart = doc[sentStart].idx\n",
    "    leftPartEnd = doc[firstTokenIndex].idx\n",
    "    rightPartStart = doc[lastTokenIndex].idx + len(doc[lastTokenIndex])\n",
    "    rightPartEnd = doc[sentEnd - 1].idx + len(doc[sentEnd - 1])\n",
    "    \n",
    "    question = doc.text[leftPartStart:leftPartEnd] + '_____' + doc.text[rightPartStart:rightPartEnd]\n",
    "    \n",
    "    return question\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Grouping questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addQuestions(answers, text):\n",
    "    doc = nlp(text)\n",
    "    currAnswerIndex = 0\n",
    "    qaPair = []\n",
    "\n",
    "    #Check wheter each token is the next answer\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            \n",
    "            #If all the answers have been found, stop looking\n",
    "            if currAnswerIndex >= len(answers):\n",
    "                break\n",
    "            \n",
    "            #In the case where the answer is consisted of more than one token, check the following tokens as well.\n",
    "            answerDoc = nlp(answers[currAnswerIndex]['word'])\n",
    "            answerIsFound = True\n",
    "            \n",
    "            for j in range(len(answerDoc)):\n",
    "                if token.i + j >= len(doc) or doc[token.i + j].text != answerDoc[j].text:\n",
    "                    answerIsFound = False\n",
    "           \n",
    "            #If the current token is corresponding with the answer, add it \n",
    "            if answerIsFound:\n",
    "                question = blankAnswer(token.i, token.i + len(answerDoc) - 1, sent.start, sent.end, doc)\n",
    "                \n",
    "                qaPair.append({'question' : question, 'answer': answers[currAnswerIndex]['word'], 'prob': answers[currAnswerIndex]['prob']})\n",
    "                \n",
    "                currAnswerIndex += 1\n",
    "                \n",
    "    return qaPair "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortAnswers(qaPairs):\n",
    "    orderedQaPairs = sorted(qaPairs, key=lambda qaPair: qaPair['prob'])\n",
    "    \n",
    "    return orderedQaPairs     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Generating Distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "glove_file = vAR_Training_Data1\n",
    "tmp_file = vAR_Training_Data2\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_file, tmp_file)\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distractors(answer, count):\n",
    "    answer = str.lower(answer)\n",
    "    \n",
    "    ##Extracting closest words for the answer. \n",
    "    try:\n",
    "        closestWords = model.most_similar(positive=[answer], topn=count)\n",
    "    except:\n",
    "        #In case the word is not in the vocabulary, or other problem not loading embeddings\n",
    "        return []\n",
    "\n",
    "    #Return count many distractors\n",
    "    distractors = list(map(lambda x: x[0], closestWords))[0:count]\n",
    "    \n",
    "    return distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDistractors(qaPairs, count):\n",
    "    for qaPair in qaPairs:\n",
    "        distractors = generate_distractors(qaPair['answer'], count)\n",
    "        qaPair['distractors'] = distractors\n",
    "    \n",
    "    return qaPairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generateQuestions(text, count):\n",
    "    \n",
    "    ################################\n",
    "    # Extract words \n",
    "    ################################\n",
    "    df = generateDf(text)\n",
    "    wordsDf = prepareDf(df)\n",
    "    \n",
    "    ################################\n",
    "    # Predict \n",
    "    ################################\n",
    "    labeledAnswers = predictWords(wordsDf, df)\n",
    "    \n",
    "    ################################\n",
    "    # Transform questions\n",
    "    ################################\n",
    "    qaPairs = addQuestions(labeledAnswers, text)\n",
    "    \n",
    "    ################################\n",
    "    # Pick the best questions\n",
    "    ################################\n",
    "    orderedQaPairs = sortAnswers(qaPairs)\n",
    "    \n",
    "    ################################\n",
    "    # Generate distractors\n",
    "    ################################\n",
    "    questions = addDistractors(orderedQaPairs[:count], 4)\n",
    "    \n",
    "    ################################\n",
    "    # Print\n",
    "    ################################\n",
    "    for i in range(count):\n",
    "        options = []\n",
    "        options.append(questions[i]['answer'])\n",
    "        \n",
    "        display(Markdown('### Question ' + str(i + 1) + ':'))\n",
    "        print(questions[i]['question'])\n",
    "\n",
    "        \n",
    "        \n",
    "        display(Markdown('#### Options:'))\n",
    "        for distractor in questions[i]['distractors']:\n",
    "            options.append(distractor)\n",
    "#             print(distractor)\n",
    "\n",
    "       \n",
    "\n",
    "        #################################\n",
    "        # Shuffling options\n",
    "        #################################\n",
    "        \n",
    "        random.shuffle(options)\n",
    "        for num,letter in enumerate(options):\n",
    "            print(num+1,\" \",letter)\n",
    "        \n",
    "#         print(ans)\n",
    "        display(Markdown('#### Answer:'))\n",
    "        for x,correct in enumerate(options):\n",
    "            if correct==questions[i]['answer']:\n",
    "                print(x+1,correct)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Content"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of humans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and problem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines. It is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe AI could solve major challenges and crisis situations. Artificial Intelligence in business would significantly save time and effort. There is an application of robotic automation to human business tasks. Furthermore, Machine learning algorithms help in better serving customers. Chatbots provide immediate response and service to customers.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaco\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator GaussianNB from version 0.20.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 1:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence _____ to the intelligence of machines.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   commonly\n",
      "2   describes\n",
      "3   refer\n",
      "4   referred\n",
      "5   refers\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 refers\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 2:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Artificial Intelligence, machines _____ functions such as learning, planning, reasoning and problem-solving.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   performed\n",
      "2   required\n",
      "3   performing\n",
      "4   perform\n",
      "5   performs\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 perform\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 3:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Furthermore, many experts _____ AI could solve major challenges and crisis situations.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   believed\n",
      "2   know\n",
      "3   believe\n",
      "4   say\n",
      "5   think\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 believe\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 4:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Furthermore, Machine learning algorithms _____ in better serving customers.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   helps\n",
      "2   to\n",
      "3   helped\n",
      "4   helping\n",
      "5   help\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 help\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 5:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbots _____ immediate response and service to customers.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   provide\n",
      "2   providing\n",
      "3   provides\n",
      "4   help\n",
      "5   provided\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 provide\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 6:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Artificial Intelligence, machines perform functions such as learning, _____, reasoning and problem-solving.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   planned\n",
      "2   preparing\n",
      "3   plans\n",
      "4   plan\n",
      "5   planning\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 planning\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 7:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Artificial Intelligence, machines perform functions such as learning, planning, _____ and problem-solving.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   reasoning\n",
      "2   logical\n",
      "3   intuition\n",
      "4   logic\n",
      "5   deductive\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 reasoning\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 8:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is probably the fastest-growing development in the World of technology and _____.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   innovations\n",
      "2   creativity\n",
      "3   innovation\n",
      "4   entrepreneurship\n",
      "5   technological\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 innovation\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 9:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence in business would significantly save time and _____.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   efforts\n",
      "2   trying\n",
      "3   effort\n",
      "4   attempt\n",
      "5   push\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 effort\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 10:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbots provide immediate response and _____ to customers.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   service\n",
      "2   news\n",
      "3   network\n",
      "4   services\n",
      "5   .\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 service\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 11:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence in business would significantly _____ time and effort.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   help\n",
      "2   saving\n",
      "3   save\n",
      "4   saves\n",
      "5   saved\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 save\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 12:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and problem-_____.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   problem\n",
      "2   solve\n",
      "3   solving\n",
      "4   resolving\n",
      "5   solved\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 solving\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 13:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is probably the fastest-_____ development in the World of technology and innovation.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   increasing\n",
      "2   grown\n",
      "3   growing\n",
      "4   grow\n",
      "5   grew\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 growing\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 14:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Furthermore, Machine learning algorithms help in better _____ customers.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   serves\n",
      "2   served\n",
      "3   serve\n",
      "4   jail\n",
      "5   serving\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 serving\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 15:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most _____, Artificial Intelligence is the simulation of human intelligence by machines.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Options:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   accomplishment\n",
      "2   notable\n",
      "3   noteworthy\n",
      "4   accomplishments\n",
      "5   interesting\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 noteworthy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# text = \"Oxygen is a chemical element with symbol O and atomic number 8. It is a member of the chalcogen group on the periodic table, a highly reactive nonmetal, and an oxidizing agent that readily forms oxides with most elements as well as with other compounds. By mass, oxygen is the third-most abundant element in the universe, after hydrogen and helium. At standard temperature and pressure, two atoms of the element bind to form dioxygen, a colorless and odorless diatomic gas with the formula O2. Diatomic oxygen gas constitutes 20.8% of the Earth's atmosphere. As compounds including oxides, the element makes up almost half of the Earth's crust.\"\n",
    "f = open(vAR_Test_Data,mode='r')\n",
    "vAR_Content = f.read()\n",
    "display(Markdown('#### Content'))\n",
    "print(vAR_Content)\n",
    "\n",
    "print('')\n",
    "\n",
    "generateQuestions(vAR_Content, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
