{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READING INI FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# df_ = pd.read_csv(vAR_Training_Data,encoding='utf-8',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\AI\\AUTOMATIC QUESTION GENERATION\\ML\\INI\\INI_FILE_ML.ini\n",
      "C:\\AI\\AUTOMATIC QUESTION GENERATION\\ML\\TEST DATA\\NLP1.txt\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "import os\n",
    "\n",
    "vAR_Config = configparser.ConfigParser(allow_no_value=True)\n",
    "\n",
    "vAR_INI_FILE_PATH = os.getenv('AQG_INI_FILE')\n",
    "print(vAR_INI_FILE_PATH)\n",
    "\n",
    "vAR_Config.read(vAR_INI_FILE_PATH)\n",
    "\n",
    "vAR_Data = vAR_Config.sections()\n",
    "\n",
    "vAR_Config.sections()\n",
    "\n",
    "vAR_Training_Data = vAR_Config['FILE PATH']['TEST_DATA']\n",
    "print(vAR_Training_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Natural language processing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Natural language processing]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd = pd.read_csv(vAR_Training_Data,sep=' ',delimiter='|')\n",
    "df_pd\n",
    "# df_np = np.asarray(pd.read_csv(vAR_Training_Data,encoding='utf-8',header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df_pd.to_string(index=False)\n",
    "type(text)\n",
    "# text = 'Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural-language generation.Natural language processing has its roots in the 1950s.Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, a task that involves the automated interpretation and generation of natural language, but at the time not articulated as a problem separate from artificial intelligence.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Empty DataFrame\\nColumns: [Natural language processing]\\nIndex: []']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "\n",
    "sent_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'linguistics',\n",
       " ',',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'and',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'the',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'human',\n",
       " 'language',\n",
       " ',',\n",
       " 'in',\n",
       " 'particular',\n",
       " 'how',\n",
       " 'to',\n",
       " 'program',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'process',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'data.Challenges',\n",
       " 'in',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'frequently',\n",
       " 'involve',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " ',',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'understanding',\n",
       " ',',\n",
       " 'and',\n",
       " 'natural-language',\n",
       " 'generation.Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'has',\n",
       " 'its',\n",
       " 'roots',\n",
       " 'in',\n",
       " 'the',\n",
       " '1950s.Already',\n",
       " 'in',\n",
       " '1950',\n",
       " ',',\n",
       " 'Alan',\n",
       " 'Turing',\n",
       " 'published',\n",
       " 'an',\n",
       " 'article',\n",
       " 'titled',\n",
       " '``',\n",
       " 'Computing',\n",
       " 'Machinery',\n",
       " 'and',\n",
       " 'Intelligence',\n",
       " \"''\",\n",
       " 'which',\n",
       " 'proposed',\n",
       " 'what',\n",
       " 'is',\n",
       " 'now',\n",
       " 'called',\n",
       " 'the',\n",
       " 'Turing',\n",
       " 'test',\n",
       " 'as',\n",
       " 'a',\n",
       " 'criterion',\n",
       " 'of',\n",
       " 'intelligence',\n",
       " ',',\n",
       " 'a',\n",
       " 'task',\n",
       " 'that',\n",
       " 'involves',\n",
       " 'the',\n",
       " 'automated',\n",
       " 'interpretation',\n",
       " 'and',\n",
       " 'generation',\n",
       " 'of',\n",
       " 'natural',\n",
       " 'language',\n",
       " ',',\n",
       " 'but',\n",
       " 'at',\n",
       " 'the',\n",
       " 'time',\n",
       " 'not',\n",
       " 'articulated',\n",
       " 'as',\n",
       " 'a',\n",
       " 'problem',\n",
       " 'separate',\n",
       " 'from',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
