{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Data Collection - Unplanned Charges "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "\n",
    "# Step 0 - Read Data from .INI File for Hardcoded Values\n",
    "\n",
    "#import sys\n",
    "#print('Arguments:', len(sys.argv))\n",
    "#vAR_Fetched_Data_INI_File_Path = sys.argv[1]\n",
    "#print(vAR_Fetched_Data_INI_File_Path)\n",
    "\n",
    "import configparser\n",
    "vAR_Config = configparser.ConfigParser(allow_no_value=True)\n",
    "vAR_Config.read('C:/AI_POC/Lease_Formulation/DS_LEASE_ACCOUNTING_MODEL_CONS_INI_FILE.INI')\n",
    "vAR_Data = vAR_Config.sections()\n",
    "vAR_Config.sections()\n",
    "\n",
    "vAR_Fetched_Path_Train_Unplanned_Expenses = vAR_Config['PROBLEM1 CONFIGURATION']['TRAINING_DATA_UNPLANNED_EXPENSES']\n",
    "#print(vAR_Fetched_Path_Train_Unplanned_Expenses)\n",
    "\n",
    "vAR_Fetched_Path_Train_Lease_Extension = vAR_Config['PROBLEM1 CONFIGURATION']['TRAINING_DATA_LEASE_EXTENSION']\n",
    "#print(vAR_Fetched_Path_Train_Lease_Extension)\n",
    "\n",
    "vAR_Fetched_Path_Test_Unplanned_Expenses = vAR_Config['PROBLEM1 CONFIGURATION']['TEST_DATA_UNPLANNED_EXPENSES']\n",
    "#print(vAR_Fetched_Path_Test_Unplanned_Expenses)\n",
    "\n",
    "vAR_Fetched_Path_Test_Lease_Extension = vAR_Config['PROBLEM1 CONFIGURATION']['TEST_DATA_LEASE_EXTENSION']\n",
    "#print(vAR_Fetched_Path_Test_Lease_Extension)\n",
    "\n",
    "vAR_Fetched_Path_Test_Extension_Terms = vAR_Config['PROBLEM1 CONFIGURATION']['TEST_DATA_EXTENSION_TERMS']\n",
    "#print(vAR_Fetched_Path_Test_Lease_Extension)\n",
    "\n",
    "vAR_Fetched_Path_Test_IBR = vAR_Config['PROBLEM1 CONFIGURATION']['TEST_DATA_IBR']\n",
    "#print(vAR_Fetched_Path_Test_IBR)\n",
    "\n",
    "vAR_Fetched_Path_Test_Lease_Amount = vAR_Config['PROBLEM1 CONFIGURATION']['TEST_DATA_LEASE_AMOUNT']\n",
    "#print(vAR_Fetched_Path_Test_Lease_Amount)\n",
    "\n",
    "vAR_Fetched_Path_Predicted_Lease_Amount = vAR_Config['PROBLEM1 CONFIGURATION']['LEASE_AMOUNT_PREDICTION']\n",
    "#print(vAR_Fetched_Path_Predicted_Lease_Amount)\n",
    "\n",
    "vAR_Fetched_Path_Best_Fit = vAR_Config['PROBLEM1 CONFIGURATION']['BEST_FIT_DATA_PATH']\n",
    "#print(vAR_Fetched_Path_Best_Fit)\n",
    "\n",
    "vAR_Fetched_Path_Under_Fit = vAR_Config['PROBLEM1 CONFIGURATION']['UNDER_FIT_DATA_PATH']\n",
    "#print(vAR_Fetched_Path_Under_Fit)\n",
    "\n",
    "vAR_Fetched_Path_Over_Fit = vAR_Config['PROBLEM1 CONFIGURATION']['OVER_FIT_DATA_PATH']\n",
    "#print(vAR_Fetched_Path_Over_Fit)\n",
    "\n",
    "vAR_Fetched_Feature1 = vAR_Config['PROBLEM1 CONFIGURATION']['FEATURE1']\n",
    "#print(vAR_Fetched_Feature1)\n",
    "\n",
    "vAR_Fetched_Feature2 = vAR_Config['PROBLEM1 CONFIGURATION']['FEATURE2']\n",
    "#print(vAR_Fetched_Feature2)\n",
    "\n",
    "vAR_Fetched_Feature3 = vAR_Config['PROBLEM1 CONFIGURATION']['FEATURE3']\n",
    "#print(vAR_Fetched_Feature3)\n",
    "\n",
    "vAR_Fetched_Feature4 = vAR_Config['PROBLEM1 CONFIGURATION']['FEATURE4']\n",
    "#print(vAR_Fetched_Feature4)\n",
    "\n",
    "vAR_Fetched_Feature5 = vAR_Config['PROBLEM1 CONFIGURATION']['FEATURE5']\n",
    "#print(vAR_Fetched_Feature5)\n",
    "\n",
    "vAR_Fetched_Feature6 = vAR_Config['PROBLEM1 CONFIGURATION']['FEATURE6']\n",
    "#print(vAR_Fetched_Feature6)\n",
    "\n",
    "vAR_Fetched_Feature7 = vAR_Config['PROBLEM1 CONFIGURATION']['FEATURE7']\n",
    "#print(vAR_Fetched_Feature7)\n",
    "\n",
    "vAR_Fetched_Feature8 = vAR_Config['PROBLEM1 CONFIGURATION']['FEATURE8']\n",
    "#print(vAR_Fetched_Feature8)\n",
    "\n",
    "vAR_Fetched_Feature9 = vAR_Config['PROBLEM1 CONFIGURATION']['FEATURE9']\n",
    "#print(vAR_Fetched_Feature9)\n",
    "\n",
    "vAR_Fetched_Feature10 = vAR_Config['PROBLEM1 CONFIGURATION']['FEATURE10']\n",
    "#print(vAR_Fetched_Feature10)\n",
    "\n",
    "vAR_Fetched_Label1 = vAR_Config['PROBLEM1 CONFIGURATION']['LABEL1']\n",
    "#print(vAR_Fetched_Label1)\n",
    "\n",
    "vAR_Fetched_Label2 = vAR_Config['PROBLEM1 CONFIGURATION']['LABEL2']\n",
    "#print(vAR_Fetched_Label2)\n",
    "\n",
    "vAR_Fetched_Label3 = vAR_Config['PROBLEM1 CONFIGURATION']['LABEL3']\n",
    "#print(vAR_Fetched_Label3)\n",
    "\n",
    "vAR_Fetched_Label4 = vAR_Config['PROBLEM1 CONFIGURATION']['LABEL4']\n",
    "#print(vAR_Fetched_Label4)\n",
    "\n",
    "vAR_Fetched_Label5 = vAR_Config['PROBLEM1 CONFIGURATION']['LABEL5']\n",
    "#print(vAR_Fetched_Label5)\n",
    "\n",
    "import pandas as vAR_pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "vAR_df = vAR_pd.read_excel(vAR_Fetched_Path_Train_Unplanned_Expenses)\n",
    "\n",
    "vAR_Feature1 = vAR_df[vAR_Fetched_Feature1]\n",
    "vAR_Feature2 = vAR_df[vAR_Fetched_Feature2]\n",
    "vAR_Feature3 = vAR_df[vAR_Fetched_Feature3]\n",
    "vAR_Feature4 = vAR_df[vAR_Fetched_Feature4]\n",
    "vAR_Feature5 = vAR_df[vAR_Fetched_Feature5]\n",
    "vAR_Feature6 = vAR_df[vAR_Fetched_Feature6]\n",
    "vAR_Feature7 = vAR_df[vAR_Fetched_Feature7]\n",
    "vAR_Feature8 = vAR_df[vAR_Fetched_Feature8]\n",
    "vAR_Feature9 = vAR_df[vAR_Fetched_Feature9]\n",
    "vAR_Feature10 = vAR_df[vAR_Fetched_Feature10]\n",
    "\n",
    "vAR_Label1 = vAR_df[vAR_Fetched_Label1]\n",
    "vAR_Label2 = vAR_df[vAR_Fetched_Label2]\n",
    "vAR_Label3 = vAR_df[vAR_Fetched_Label3]\n",
    "vAR_Label4 = vAR_df[vAR_Fetched_Label4]\n",
    "vAR_Label5 = vAR_df[vAR_Fetched_Label5]\n",
    "\n",
    "vAR_df = vAR_df[[vAR_Fetched_Feature1,vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,vAR_Fetched_Label1]]\n",
    "vAR_le = LabelEncoder()\n",
    "vAR_Asset_Type_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,0])\n",
    "vAR_Asset_Type_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Type_Conversion,columns={'Asset_Type_Converted'})\n",
    "#vAR_Asset_Location_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,1])\n",
    "#vAR_Asset_Location_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Location_Conversion,columns={'Asset_Location_Converted'})\n",
    "\n",
    "# Attached the Converted Numerical Data to the main dataframe\n",
    "\n",
    "vAR_df1 = vAR_df.merge(vAR_Asset_Type_Conversion_df,left_index=True, right_index=True)\n",
    "#vAR_df2 = vAR_df1.merge(vAR_Asset_Location_Conversion_df,left_index=True, right_index=True)\n",
    "\n",
    "vAR_Features_Train = vAR_df1[[vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10]]\n",
    "vAR_Label_Train = vAR_df1[vAR_Fetched_Label1]\n",
    "\n",
    "\n",
    "def vAR_Collect_Train_Data_File_Unplanned_Charges():\n",
    "    \n",
    "#Import the Required Libraries\n",
    "\n",
    "    import pandas as vAR_pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    vAR_df = vAR_pd.read_excel(vAR_Fetched_Path_Train_Unplanned_Expenses)\n",
    "\n",
    "    vAR_Feature1 = vAR_df[vAR_Fetched_Feature1]\n",
    "    vAR_Feature2 = vAR_df[vAR_Fetched_Feature2]\n",
    "    vAR_Feature3 = vAR_df[vAR_Fetched_Feature3]\n",
    "    vAR_Feature4 = vAR_df[vAR_Fetched_Feature4]\n",
    "    vAR_Feature5 = vAR_df[vAR_Fetched_Feature5]\n",
    "    vAR_Feature6 = vAR_df[vAR_Fetched_Feature6]\n",
    "    vAR_Feature7 = vAR_df[vAR_Fetched_Feature7]\n",
    "    vAR_Feature8 = vAR_df[vAR_Fetched_Feature8]\n",
    "    vAR_Feature9 = vAR_df[vAR_Fetched_Feature9]\n",
    "    vAR_Feature10 = vAR_df[vAR_Fetched_Feature10]\n",
    "\n",
    "    vAR_Label1 = vAR_df[vAR_Fetched_Label1]\n",
    "    vAR_Label2 = vAR_df[vAR_Fetched_Label2]\n",
    "    vAR_Label3 = vAR_df[vAR_Fetched_Label3]\n",
    "    vAR_Label4 = vAR_df[vAR_Fetched_Label4]\n",
    "    vAR_Label5 = vAR_df[vAR_Fetched_Label5]\n",
    "\n",
    "    vAR_df = vAR_df[[vAR_Fetched_Feature1,vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,vAR_Fetched_Label1]]\n",
    "    vAR_le = LabelEncoder()\n",
    "    vAR_Asset_Type_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,0])\n",
    "    vAR_Asset_Type_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Type_Conversion,columns={'Asset_Type_Converted'})\n",
    "    #vAR_Asset_Location_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,1])\n",
    "    #vAR_Asset_Location_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Location_Conversion,columns={'Asset_Location_Converted'})\n",
    "\n",
    "# Attached the Converted Numerical Data to the main dataframe\n",
    "\n",
    "    vAR_df1 = vAR_df.merge(vAR_Asset_Type_Conversion_df,left_index=True, right_index=True)\n",
    "    #vAR_df2 = vAR_df1.merge(vAR_Asset_Location_Conversion_df,left_index=True, right_index=True)\n",
    "\n",
    "    vAR_Features_Train = vAR_df1[[vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10]]\n",
    "    vAR_Label_Train = vAR_df1[vAR_Fetched_Label1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Unplanned Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_File_Unplanned_Charges():\n",
    "    \n",
    "#Import the Required Libraries\n",
    "\n",
    "    import pandas as vAR_pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
    "\n",
    "# Step 2 - Import Training Data\n",
    "\n",
    "#Next step after importing all libraries is getting the Training data imported. \n",
    "\n",
    "#We are importing the Clustering data stored in our local system with the use of Pandas library.\n",
    "\n",
    "    vAR_df = vAR_pd.read_excel(vAR_Fetched_Path_Train_Unplanned_Expenses)\n",
    "\n",
    "    vAR_Feature1 = vAR_df[vAR_Fetched_Feature1]\n",
    "    vAR_Feature2 = vAR_df[vAR_Fetched_Feature2]\n",
    "    vAR_Feature3 = vAR_df[vAR_Fetched_Feature3]\n",
    "    vAR_Feature4 = vAR_df[vAR_Fetched_Feature4]\n",
    "    vAR_Feature5 = vAR_df[vAR_Fetched_Feature5]\n",
    "    vAR_Feature6 = vAR_df[vAR_Fetched_Feature6]\n",
    "    vAR_Feature7 = vAR_df[vAR_Fetched_Feature7]\n",
    "    vAR_Feature8 = vAR_df[vAR_Fetched_Feature8]\n",
    "    vAR_Feature9 = vAR_df[vAR_Fetched_Feature9]\n",
    "    vAR_Feature10 = vAR_df[vAR_Fetched_Feature10]\n",
    "\n",
    "    vAR_Label1 = vAR_df[vAR_Fetched_Label1]\n",
    "    vAR_Label2 = vAR_df[vAR_Fetched_Label2]\n",
    "    vAR_Label3 = vAR_df[vAR_Fetched_Label3]\n",
    "    vAR_Label4 = vAR_df[vAR_Fetched_Label4]\n",
    "    vAR_Label5 = vAR_df[vAR_Fetched_Label5]\n",
    "\n",
    "    vAR_df = vAR_df[[vAR_Fetched_Feature1,vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,vAR_Fetched_Label1]]\n",
    "    vAR_le = LabelEncoder()\n",
    "    vAR_Asset_Type_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,0])\n",
    "    vAR_Asset_Type_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Type_Conversion,columns={'Asset_Type_Converted'})\n",
    "    #vAR_Asset_Location_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,1])\n",
    "    #vAR_Asset_Location_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Location_Conversion,columns={'Asset_Location_Converted'})\n",
    "\n",
    "# Attached the Converted Numerical Data to the main dataframe\n",
    "\n",
    "    vAR_df1 = vAR_df.merge(vAR_Asset_Type_Conversion_df,left_index=True, right_index=True)\n",
    "    #vAR_df2 = vAR_df1.merge(vAR_Asset_Location_Conversion_df,left_index=True, right_index=True)\n",
    "\n",
    "    vAR_Features_Train = vAR_df1[[vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10]]\n",
    "    vAR_Label_Train = vAR_df1[vAR_Fetched_Label1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Unplanned Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_File_Unplanned_Charges():\n",
    "    \n",
    "# Importing the Test Data is to check how the data used on the Model Performs\n",
    "\n",
    "    vAR_df3 = vAR_pd.read_excel(vAR_Fetched_Path_Test_Unplanned_Expenses)\n",
    "    vAR_df3 = vAR_df3[[vAR_Fetched_Feature1,vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10]]\n",
    "    vAR_le = LabelEncoder()\n",
    "    vAR_Asset_Type_Conversion = vAR_le.fit_transform(vAR_df3.iloc[:,0])\n",
    "    vAR_Asset_Type_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Type_Conversion,columns={'Asset_Type_Converted'})\n",
    "    \n",
    "# Attached the Converted Numerical Data to the main dataframe\n",
    "\n",
    "    vAR_df4 = vAR_df3.merge(vAR_Asset_Type_Conversion_df,left_index=True, right_index=True)\n",
    "    \n",
    "    vAR_Features_Test = vAR_df4[[vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Unplanned Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_Hadoop_Unplanned_Charges():\n",
    "\n",
    "    import pypyodbc as pyodbc\n",
    "\n",
    "    #vAR_CSLAB_CONN = pyodbc.connect(''DSN=vAR_HADOOP;UID=vAR_USER;PWD=vAR_PW',autocommit=True)\n",
    "\n",
    "    #vAR_CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "    #vAR_CSLAB_STMNT = 'SELECT * FROM TRAINING_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "    #vAR_CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "    #vAR_CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Unplanned Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_Hadoop_Unplanned_Charges():\n",
    "\n",
    "    import pypyodbc as pyodbc\n",
    "\n",
    "#vAR_CSLAB_CONN = pyodbc.connect('DSN=vAR_HADOOP;UID=vAR_USER;PWD=vAR_PW',autocommit=True)\n",
    "\n",
    "#vAR_CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#vAR_CSLAB_STMNT = 'SELECT * FROM TEST_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "#vAR_CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#vAR_CSLAB_RESULT = CSLAB_CURSOR.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From SAP HANA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Unplanned Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_SAPHANA_Unplanned_Charges():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_SAPHANA;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Unplanned Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_SAPHANA_Unplanned_Charges():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_SAPHANA;UID=vAR_USER;PWD=vAR_PW'')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Unplanned Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_Oracle_Unplanned_Charges():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_ORACLE;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Test Data - Unplanned Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_Oracle_Unplanned_Charges():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_ORACLE;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Unplanned Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_MSSQL_Unplanned_Charges():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_MSSQL;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Unplanned Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_MSSQL_Unplanned_Charges():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_MSSQL;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Lease Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_File_Lease_Extension():\n",
    "    \n",
    "    import pandas as vAR_pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    vAR_df = vAR_pd.read_excel(vAR_Fetched_Path_Train_Unplanned_Expenses)\n",
    "\n",
    "    vAR_Feature1 = vAR_df[vAR_Fetched_Feature1]\n",
    "    vAR_Feature2 = vAR_df[vAR_Fetched_Feature2]\n",
    "    vAR_Feature3 = vAR_df[vAR_Fetched_Feature3]\n",
    "    vAR_Feature4 = vAR_df[vAR_Fetched_Feature4]\n",
    "    vAR_Feature5 = vAR_df[vAR_Fetched_Feature5]\n",
    "    vAR_Feature6 = vAR_df[vAR_Fetched_Feature6]\n",
    "    vAR_Feature7 = vAR_df[vAR_Fetched_Feature7]\n",
    "    vAR_Feature8 = vAR_df[vAR_Fetched_Feature8]\n",
    "    vAR_Feature9 = vAR_df[vAR_Fetched_Feature9]\n",
    "    vAR_Feature10 = vAR_df[vAR_Fetched_Feature10]\n",
    "\n",
    "    vAR_Label1 = vAR_df[vAR_Fetched_Label1]\n",
    "    vAR_Label2 = vAR_df[vAR_Fetched_Label2]\n",
    "    vAR_Label3 = vAR_df[vAR_Fetched_Label3]\n",
    "    vAR_Label4 = vAR_df[vAR_Fetched_Label4]\n",
    "    vAR_Label5 = vAR_df[vAR_Fetched_Label5]\n",
    "\n",
    "    vAR_df = vAR_df[[vAR_Fetched_Feature1,vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,vAR_Fetched_Label1,vAR_Fetched_Label2]]\n",
    "    vAR_le = LabelEncoder()\n",
    "    vAR_Asset_Type_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,0])\n",
    "    vAR_Asset_Type_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Type_Conversion,columns={'Asset_Type_Converted'})\n",
    "    #vAR_Asset_Location_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,1])\n",
    "    #vAR_Asset_Location_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Location_Conversion,columns={'Asset_Location_Converted'})\n",
    "\n",
    "    # Attached the Converted Numerical Data to the main dataframe\n",
    "\n",
    "    vAR_df1 = vAR_df.merge(vAR_Asset_Type_Conversion_df,left_index=True, right_index=True)\n",
    "    #vAR_df2 = vAR_df1.merge(vAR_Asset_Location_Conversion_df,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Lease Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_File_Lease_Extension():\n",
    "    \n",
    "# Importing the Test Data is to check how the data used on the Model Performs\n",
    "\n",
    "    vAR_df3 = vAR_pd.read_excel(vAR_Fetched_Path_Test_Lease_Extension)\n",
    "    vAR_df3 = vAR_df3[[vAR_Fetched_Feature1,vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,'Predicted_Unplanned_Charges']]\n",
    "\n",
    "    vAR_le = LabelEncoder()\n",
    "    vAR_Asset_Type_Conversion = vAR_le.fit_transform(vAR_df3.iloc[:,0])\n",
    "    vAR_Asset_Type_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Type_Conversion,columns={'Asset_Type_Converted'})\n",
    "    \n",
    "# Attached the Converted Numerical Data to the main dataframe\n",
    "\n",
    "    vAR_df4 = vAR_df3.merge(vAR_Asset_Type_Conversion_df,left_index=True, right_index=True)\n",
    "#vAR_df4\n",
    "\n",
    "    vAR_Features_Test2 = vAR_df4[[vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,'Predicted_Unplanned_Charges']]\n",
    "\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Lease Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_Hadoop_Lease_Extension():\n",
    "    \n",
    "    import pypyodbc as pyodbc\n",
    "\n",
    "#vAR_CSLAB_CONN = pyodbc.connect(''DSN=vAR_HADOOP;UID=vAR_USER;PWD=vAR_PW',autocommit=True)\n",
    "\n",
    "#vAR_CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#vAR_CSLAB_STMNT = 'SELECT * FROM TRAINING_DATA_LEASE_EXTENSION'\n",
    "\n",
    "#vAR_CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#vAR_CSLAB_RESULT = CSLAB_CURSOR.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Lease Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_Hadoop_Lease_Extension():\n",
    "    \n",
    "    import pypyodbc as pyodbc\n",
    "\n",
    "#vAR_CSLAB_CONN = pyodbc.connect(''DSN=vAR_HADOOP;UID=vAR_USER;PWD=vAR_PW',autocommit=True)\n",
    "\n",
    "#vAR_CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#vAR_CSLAB_STMNT = 'SELECT * FROM TEST_DATA_LEASE_EXTENSION'\n",
    "\n",
    "#vAR_CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#vAR_CSLAB_RESULT = CSLAB_CURSOR.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From SAP HANA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Lease Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_SAPHANA_Lease_Extension():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_SAPHANA;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Lease Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_SAPHANA_Lease_Extension():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_SAPHANA;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TEST_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Lease Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_Oracle_Lease_Extension():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_ORACLE;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Lease Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_Oracle_Lease_Extension():\n",
    "        \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_ORACLE;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TEST_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MS SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Lease Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_MSSQL_Lease_Extension():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_MSSQL;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Lease Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_MSSQL_Lease_Extension():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_MSSQL;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TEST_DATA_UNPLANNED_EXPENSES'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Extension Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_File_Extension_Terms():\n",
    "    \n",
    "    import pandas as vAR_pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    vAR_df = vAR_pd.read_excel(vAR_Fetched_Path_Train_Unplanned_Expenses)\n",
    "\n",
    "    vAR_Feature1 = vAR_df[vAR_Fetched_Feature1]\n",
    "    vAR_Feature2 = vAR_df[vAR_Fetched_Feature2]\n",
    "    vAR_Feature3 = vAR_df[vAR_Fetched_Feature3]\n",
    "    vAR_Feature4 = vAR_df[vAR_Fetched_Feature4]\n",
    "    vAR_Feature5 = vAR_df[vAR_Fetched_Feature5]\n",
    "    vAR_Feature6 = vAR_df[vAR_Fetched_Feature6]\n",
    "    vAR_Feature7 = vAR_df[vAR_Fetched_Feature7]\n",
    "    vAR_Feature8 = vAR_df[vAR_Fetched_Feature8]\n",
    "    vAR_Feature9 = vAR_df[vAR_Fetched_Feature9]\n",
    "    vAR_Feature10 = vAR_df[vAR_Fetched_Feature10]\n",
    "\n",
    "    vAR_Label1 = vAR_df[vAR_Fetched_Label1]\n",
    "    vAR_Label2 = vAR_df[vAR_Fetched_Label2]\n",
    "    vAR_Label3 = vAR_df[vAR_Fetched_Label3]\n",
    "    vAR_Label4 = vAR_df[vAR_Fetched_Label4]\n",
    "    vAR_Label5 = vAR_df[vAR_Fetched_Label5]\n",
    "\n",
    "    vAR_df = vAR_df[[vAR_Fetched_Feature1,vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,vAR_Fetched_Label1,vAR_Fetched_Label2,vAR_Fetched_Label3]]\n",
    "    vAR_le = LabelEncoder()\n",
    "    vAR_Asset_Type_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,0])\n",
    "    vAR_Asset_Type_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Type_Conversion,columns={'Asset_Type_Converted'})\n",
    "    #vAR_Asset_Location_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,1])\n",
    "    #vAR_Asset_Location_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Location_Conversion,columns={'Asset_Location_Converted'})\n",
    "\n",
    "# Attached the Converted Numerical Data to the main dataframe\n",
    "\n",
    "    vAR_df1 = vAR_df.merge(vAR_Asset_Type_Conversion_df,left_index=True, right_index=True)\n",
    "    #vAR_df2 = vAR_df1.merge(vAR_Asset_Location_Conversion_df,left_index=True, right_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Extension Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_File_Extension_Terms():\n",
    "\n",
    "    vAR_df3 = vAR_pd.read_excel(vAR_Fetched_Path_Test_Extension_Terms)\n",
    "    vAR_df3 = vAR_df3[[vAR_Fetched_Feature1,vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,'Predicted_Unplanned_Charges','Predicted_Lease_Extension']]\n",
    "\n",
    "    vAR_le = LabelEncoder()\n",
    "    vAR_Asset_Type_Conversion = vAR_le.fit_transform(vAR_df3.iloc[:,0])\n",
    "    vAR_Asset_Type_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Type_Conversion,columns={'Asset_Type_Converted'})\n",
    "    \n",
    "# Attached the Converted Numerical Data to the main dataframe\n",
    "\n",
    "    vAR_df4 = vAR_df3.merge(vAR_Asset_Type_Conversion_df,left_index=True, right_index=True)\n",
    "#vAR_df4\n",
    "\n",
    "    vAR_Features_Test2 = vAR_df4[[vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,'Predicted_Unplanned_Charges','Predicted_Lease_Extension']]\n",
    "    vAR_Features_Test2 = vAR_Features_Test2.loc[vAR_Features_Test2['Predicted_Lease_Extension'] == 1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Extension Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_Hadoop_Extension_Terms():\n",
    "\n",
    "    import pypyodbc as pyodbc\n",
    "\n",
    "#vAR_CSLAB_CONN = pyodbc.connect(''DSN=vAR_HADOOP;UID=vAR_USER;PWD=vAR_PW',autocommit=True)\n",
    "\n",
    "#vAR_CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#vAR_CSLAB_STMNT = 'SELECT * FROM TRAINING_DATA_EXTENSION_TERMS'\n",
    "\n",
    "#vAR_CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#vAR_CSLAB_RESULT = CSLAB_CURSOR.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Extension Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_Hadoop_Extension_Terms():\n",
    "    \n",
    "    import pypyodbc as pyodbc\n",
    "\n",
    "#vAR_CSLAB_CONN = pyodbc.connect(''DSN=vAR_HADOOP;UID=vAR_USER;PWD=vAR_PW',autocommit=True)\n",
    "\n",
    "#vAR_CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#vAR_CSLAB_STMNT = 'SELECT * FROM TEST_DATA_EXTENSION_TERMS'\n",
    "\n",
    "#vAR_CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#vAR_CSLAB_RESULT = CSLAB_CURSOR.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAP HANA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Extension Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_SAPHANA_Extension_Terms():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_SAPHANA;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TEST_DATA_EXTENSION_TERMS'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Extension Terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_SAPHANA_Extension_Terms():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_SAPHANA;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TEST_DATA_EXTENSION_TERMS'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Extension Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_Oracle_Extension_Terms():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_ORACLE;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_EXTENSION_TERMS'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Extension Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_Oracle_Extension_Terms():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_ORACLE;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TEST_DATA_EXTENSION_TERMS'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MS SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Extension Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_MSSQL_Extension_Terms():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_MSSQL;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_EXTENSION_TERMS'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Extension Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_MSSQL_Extension_Terms():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_MSSQL;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TEST_DATA_EXTENSION_TERMS'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - IBR %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_File_IBR():\n",
    "    \n",
    "    import pandas as vAR_pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    vAR_df = vAR_pd.read_excel(vAR_Fetched_Path_Train_Unplanned_Expenses)\n",
    "\n",
    "    vAR_Feature1 = vAR_df[vAR_Fetched_Feature1]\n",
    "    vAR_Feature2 = vAR_df[vAR_Fetched_Feature2]\n",
    "    vAR_Feature3 = vAR_df[vAR_Fetched_Feature3]\n",
    "    vAR_Feature4 = vAR_df[vAR_Fetched_Feature4]\n",
    "    vAR_Feature5 = vAR_df[vAR_Fetched_Feature5]\n",
    "    vAR_Feature6 = vAR_df[vAR_Fetched_Feature6]\n",
    "    vAR_Feature7 = vAR_df[vAR_Fetched_Feature7]\n",
    "    vAR_Feature8 = vAR_df[vAR_Fetched_Feature8]\n",
    "    vAR_Feature9 = vAR_df[vAR_Fetched_Feature9]\n",
    "    vAR_Feature10 = vAR_df[vAR_Fetched_Feature10]\n",
    "\n",
    "    vAR_Label1 = vAR_df[vAR_Fetched_Label1]\n",
    "    vAR_Label2 = vAR_df[vAR_Fetched_Label2]\n",
    "    vAR_Label3 = vAR_df[vAR_Fetched_Label3]\n",
    "    vAR_Label4 = vAR_df[vAR_Fetched_Label4]\n",
    "    vAR_Label5 = vAR_df[vAR_Fetched_Label5]\n",
    "\n",
    "    vAR_df = vAR_df[[vAR_Fetched_Feature1,vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,vAR_Fetched_Label1,vAR_Fetched_Label2,vAR_Fetched_Label3,vAR_Fetched_Label4]]\n",
    "    vAR_le = LabelEncoder()\n",
    "    vAR_Asset_Type_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,0])\n",
    "    vAR_Asset_Type_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Type_Conversion,columns={'Asset_Type_Converted'})\n",
    "    #vAR_Asset_Location_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,1])\n",
    "    #vAR_Asset_Location_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Location_Conversion,columns={'Asset_Location_Converted'})\n",
    "\n",
    "# Attached the Converted Numerical Data to the main dataframe\n",
    "\n",
    "    vAR_df1 = vAR_df.merge(vAR_Asset_Type_Conversion_df,left_index=True, right_index=True)\n",
    "    #vAR_df2 = vAR_df1.merge(vAR_Asset_Location_Conversion_df,left_index=True, right_index=True)\n",
    "\n",
    "    vAR_Features_Train4 = vAR_df1[[vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,vAR_Fetched_Label1,vAR_Fetched_Label2,vAR_Fetched_Label3]]\n",
    "    vAR_Label_Train4 = vAR_df1[vAR_Fetched_Label4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - IBR %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_File_IBR():\n",
    "    vAR_df3 = vAR_pd.read_excel(vAR_Fetched_Path_Test_IBR)\n",
    "    vAR_df3 = vAR_df3[[vAR_Fetched_Feature1,vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,'Predicted_Unplanned_Charges','Predicted_Lease_Extension','Predicted_Extension_Terms']]\n",
    "\n",
    "    vAR_le = LabelEncoder()\n",
    "    vAR_Asset_Type_Conversion = vAR_le.fit_transform(vAR_df3.iloc[:,0])\n",
    "    vAR_Asset_Type_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Type_Conversion,columns={'Asset_Type_Converted'})\n",
    "    \n",
    "# Attached the Converted Numerical Data to the main dataframe\n",
    "\n",
    "    vAR_df4 = vAR_df3.merge(vAR_Asset_Type_Conversion_df,left_index=True, right_index=True)\n",
    "#vAR_df4\n",
    "\n",
    "    vAR_Features_Test2 = vAR_df4[[vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,'Predicted_Unplanned_Charges','Predicted_Lease_Extension','Predicted_Extension_Terms']]\n",
    "    vAR_Features_Test2 = vAR_Features_Test2.loc[vAR_Features_Test2['Predicted_Lease_Extension'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - IBR %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_Hadoop_IBR():\n",
    "    \n",
    "    import pypyodbc as pyodbc\n",
    "\n",
    "#vAR_CSLAB_CONN = pyodbc.connect(''DSN=vAR_HADOOP;UID=vAR_USER;PWD=vAR_PW',autocommit=True)\n",
    "\n",
    "#vAR_CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#vAR_CSLAB_STMNT = 'SELECT * FROM TRAINING_DATA_IBR'\n",
    "\n",
    "#vAR_CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#vAR_CSLAB_RESULT = CSLAB_CURSOR.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - IBR %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_Hadoop_IBR():\n",
    "    \n",
    "    import pypyodbc as pyodbc\n",
    "\n",
    "#vAR_CSLAB_CONN = pyodbc.connect(''DSN=vAR_HADOOP;UID=vAR_USER;PWD=vAR_PW',autocommit=True)\n",
    "\n",
    "#vAR_CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#vAR_CSLAB_STMNT = 'SELECT * FROM TEST_DATA_IBR'\n",
    "\n",
    "#vAR_CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#vAR_CSLAB_RESULT = CSLAB_CURSOR.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From SAP HANA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - IBR %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_SAPHANA_IBR():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_SAPHANA;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_IBR'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - IBR %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_SAPHANA_IBR():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_SAPHANA;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TEST_DATA_IBR'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - IBR %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_Oracle_IBR():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_ORACLE;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_IBR'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - IBR %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_Oracle_IBR():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_ORACLE;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TEST_DATA_IBR'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From MS SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - IBR %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_MSSQL_IBR():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_MSSQL;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_IBR'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - IBR %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_MSSQL_IBR():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_MSSQL;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TEST_DATA_IBR'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Lease Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_File_Lease_Amount():\n",
    "    \n",
    "    import pandas as vAR_pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    vAR_df = vAR_pd.read_excel(vAR_Fetched_Path_Train_Unplanned_Expenses)\n",
    "\n",
    "    vAR_Feature1 = vAR_df[vAR_Fetched_Feature1]\n",
    "    vAR_Feature2 = vAR_df[vAR_Fetched_Feature2]\n",
    "    vAR_Feature3 = vAR_df[vAR_Fetched_Feature3]\n",
    "    vAR_Feature4 = vAR_df[vAR_Fetched_Feature4]\n",
    "    vAR_Feature5 = vAR_df[vAR_Fetched_Feature5]\n",
    "    vAR_Feature6 = vAR_df[vAR_Fetched_Feature6]\n",
    "    vAR_Feature7 = vAR_df[vAR_Fetched_Feature7]\n",
    "    vAR_Feature8 = vAR_df[vAR_Fetched_Feature8]\n",
    "    vAR_Feature9 = vAR_df[vAR_Fetched_Feature9]\n",
    "    vAR_Feature10 = vAR_df[vAR_Fetched_Feature10]\n",
    "\n",
    "    vAR_Label1 = vAR_df[vAR_Fetched_Label1]\n",
    "    vAR_Label2 = vAR_df[vAR_Fetched_Label2]\n",
    "    vAR_Label3 = vAR_df[vAR_Fetched_Label3]\n",
    "    vAR_Label4 = vAR_df[vAR_Fetched_Label4]\n",
    "    vAR_Label5 = vAR_df[vAR_Fetched_Label5]\n",
    "\n",
    "    vAR_df = vAR_df[[vAR_Fetched_Feature1,vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,vAR_Fetched_Label1,vAR_Fetched_Label2,vAR_Fetched_Label3,vAR_Fetched_Label4,vAR_Fetched_Label5]]\n",
    "    vAR_le = LabelEncoder()\n",
    "    vAR_Asset_Type_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,0])\n",
    "    vAR_Asset_Type_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Type_Conversion,columns={'Asset_Type_Converted'})\n",
    "    #vAR_Asset_Location_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,1])\n",
    "    #vAR_Asset_Location_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Location_Conversion,columns={'Asset_Location_Converted'})\n",
    "\n",
    "    # Attached the Converted Numerical Data to the main dataframe\n",
    "\n",
    "    vAR_df1 = vAR_df.merge(vAR_Asset_Type_Conversion_df,left_index=True, right_index=True)\n",
    "    #vAR_df2 = vAR_df1.merge(vAR_Asset_Location_Conversion_df,left_index=True, right_index=True)\n",
    "\n",
    "    vAR_Features_Train5 = vAR_df1[[vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,vAR_Fetched_Label1,vAR_Fetched_Label2,vAR_Fetched_Label3,vAR_Fetched_Label4]]\n",
    "    vAR_Label_Train5 = vAR_df1[vAR_Fetched_Label5]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Lease Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_File_Lease_Amount():\n",
    "    \n",
    "    vAR_df3 = vAR_pd.read_excel(vAR_Fetched_Path_Test_Lease_Amount)\n",
    "    vAR_df3 = vAR_df3[[vAR_Fetched_Feature1,vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,'Predicted_Unplanned_Charges','Predicted_Lease_Extension','Predicted_Extension_Terms','Predicted_IBR']]\n",
    "\n",
    "    vAR_le = LabelEncoder()\n",
    "    vAR_Asset_Type_Conversion = vAR_le.fit_transform(vAR_df3.iloc[:,0])\n",
    "    vAR_Asset_Type_Conversion_df = vAR_pd.DataFrame(vAR_Asset_Type_Conversion,columns={'Asset_Type_Converted'})\n",
    "    \n",
    "# Attached the Converted Numerical Data to the main dataframe\n",
    "\n",
    "    vAR_df4 = vAR_df3.merge(vAR_Asset_Type_Conversion_df,left_index=True, right_index=True)\n",
    "#vAR_df4\n",
    "\n",
    "    vAR_Features_Test2 = vAR_df4[[vAR_Fetched_Feature2,vAR_Fetched_Feature3,vAR_Fetched_Feature4,vAR_Fetched_Feature5,vAR_Fetched_Feature6,vAR_Fetched_Feature7,vAR_Fetched_Feature8,vAR_Fetched_Feature9,vAR_Fetched_Feature10,'Predicted_Unplanned_Charges','Predicted_Lease_Extension','Predicted_Extension_Terms','Predicted_IBR']]\n",
    "    vAR_Features_Test2 = vAR_Features_Test2.loc[vAR_Features_Test2['Predicted_Lease_Extension'] == 1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Lease Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_Hadoop_Lease_Amount():\n",
    "    \n",
    "    import pypyodbc as pyodbc\n",
    "\n",
    "#vAR_CSLAB_CONN = pyodbc.connect(''DSN=vAR_HADOOP;UID=vAR_USER;PWD=vAR_PW',autocommit=True)\n",
    "\n",
    "#vAR_CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#vAR_CSLAB_STMNT = 'SELECT * FROM TRAINING_DATA_LEASE_AMOUNT'\n",
    "\n",
    "#vAR_CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#vAR_CSLAB_RESULT = CSLAB_CURSOR.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Lease Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_Hadoop_Lease_Amount():\n",
    "    \n",
    "    import pypyodbc as pyodbc\n",
    "\n",
    "#vAR_CSLAB_CONN = pyodbc.connect(''DSN=vAR_HADOOP;UID=vAR_USER;PWD=vAR_PW',autocommit=True)\n",
    "\n",
    "#vAR_CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#vAR_CSLAB_STMNT = 'SELECT * FROM TEST_DATA_LEASE_AMOUNT'\n",
    "\n",
    "#vAR_CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#vAR_CSLAB_RESULT = CSLAB_CURSOR.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAP HANA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Lease Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_SAPHANA_Lease_Amount():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_SAPHANA;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_LEASE_AMOUNT'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Lease Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_SAPHANA_Lease_Amount():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_SAPHANA;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_LEASE_AMOUNT'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Lease Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_Oracle_Lease_Amount():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_ORACLE;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_LEASE_AMOUNT'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Lease Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_Oracle_Lease_Amount():\n",
    "\n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_ORACLE;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TEST_DATA_LEASE_AMOUNT'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Training Data - Lease Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Train_Data_MSSQL_Lease_Amount():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_MSSQL;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TRAINING_DATA_LEASE_AMOUNT'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Importing Test Data - Lease Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Collect_Test_Data_MSSQL_Lease_Amount():\n",
    "    \n",
    "    import pypyodbc as pyodbc \n",
    "\n",
    "#CSLAB_CONN = pyodbc.connect('DSN=vAR_MSSQL;UID=vAR_USER;PWD=vAR_PW')\n",
    "\n",
    "#CSLAB_CURSOR = CSLAB_CONN.cursor()\n",
    "\n",
    "#CSLAB_STMNT = 'SELECT * FROM DURGA.TEST_DATA_LEASE_AMOUNT'\n",
    "\n",
    "#CSLAB_CURSOR.execute(CSLAB_STMNT)\n",
    "\n",
    "#CSLAB_RESULT = CSLAB_CURSOR.fetchall()\n",
    "\n",
    "#print (CSLAB_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Train Data from all Sources (Unplanned Charges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "vAR_Collect_Train_Data_File_Unplanned_Charges() \n",
    "vAR_df_UC = vAR_df1 # +vAR_Collect_Train_Data_Hadoop_Unplanned_Charges()+vAR_Collect_Train_Data_SAPHANA_Unplanned_Charges()++vAR_Collect_Train_Data_Oracle_Unplanned_Charges()++vAR_Collect_Train_Data_MSSQL_Unplanned_Charges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Integrate_Train_Data_Unplanned_Charges():\n",
    "    vAR_Collect_Train_Data_File_Unplanned_Charges() \n",
    "    vAR_df_UC = vAR_df1 # +vAR_Collect_Train_Data_Hadoop_Unplanned_Charges()+vAR_Collect_Train_Data_SAPHANA_Unplanned_Charges()++vAR_Collect_Train_Data_Oracle_Unplanned_Charges()++vAR_Collect_Train_Data_MSSQL_Unplanned_Charges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "vAR_Integrate_Train_Data_Unplanned_Charges()\n",
    "#vAR_df_UC.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Train Data from all Sources (Lease Extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "vAR_Collect_Train_Data_File_Lease_Extension() \n",
    "vAR_df_LE = vAR_df1 # +vAR_Collect_Train_Data_Hadoop_Unplanned_Charges()+vAR_Collect_Train_Data_SAPHANA_Unplanned_Charges()++vAR_Collect_Train_Data_Oracle_Unplanned_Charges()++vAR_Collect_Train_Data_MSSQL_Unplanned_Charges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Integrate_Train_Data_Lease_Extension():\n",
    "    vAR_Collect_Train_Data_File_Lease_Extension() \n",
    "    vAR_df_LE = vAR_df1 # +vAR_Collect_Train_Data_Hadoop_Unplanned_Charges()+vAR_Collect_Train_Data_SAPHANA_Unplanned_Charges()++vAR_Collect_Train_Data_Oracle_Unplanned_Charges()++vAR_Collect_Train_Data_MSSQL_Unplanned_Charges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "vAR_Collect_Train_Data_File_Lease_Extension()\n",
    "#vAR_df_LE.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Train Data from all Sources (Extension Terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "vAR_Collect_Train_Data_File_Extension_Terms() \n",
    "vAR_df_ET = vAR_df1 # +vAR_Collect_Train_Data_Hadoop_Unplanned_Charges()+vAR_Collect_Train_Data_SAPHANA_Unplanned_Charges()++vAR_Collect_Train_Data_Oracle_Unplanned_Charges()++vAR_Collect_Train_Data_MSSQL_Unplanned_Charges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Integrate_Train_Data_Extension_Terms():\n",
    "    vAR_Collect_Train_Data_File_Extension_Terms() \n",
    "    vAR_df_ET = vAR_df1 # +vAR_Collect_Train_Data_Hadoop_Unplanned_Charges()+vAR_Collect_Train_Data_SAPHANA_Unplanned_Charges()++vAR_Collect_Train_Data_Oracle_Unplanned_Charges()++vAR_Collect_Train_Data_MSSQL_Unplanned_Charges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "vAR_Collect_Train_Data_File_Extension_Terms()\n",
    "#vAR_df_ET.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Train Data from all Sources (IBR %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "vAR_Collect_Train_Data_File_IBR() \n",
    "vAR_df_IBR = vAR_df1 # +vAR_Collect_Train_Data_Hadoop_Unplanned_Charges()+vAR_Collect_Train_Data_SAPHANA_Unplanned_Charges()++vAR_Collect_Train_Data_Oracle_Unplanned_Charges()++vAR_Collect_Train_Data_MSSQL_Unplanned_Charges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Integrate_Train_Data_IBR():\n",
    "    vAR_Collect_Train_Data_File_IBR() \n",
    "    vAR_df_IBR = vAR_df1 # +vAR_Collect_Train_Data_Hadoop_Unplanned_Charges()+vAR_Collect_Train_Data_SAPHANA_Unplanned_Charges()++vAR_Collect_Train_Data_Oracle_Unplanned_Charges()++vAR_Collect_Train_Data_MSSQL_Unplanned_Charges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "vAR_Integrate_Train_Data_IBR()\n",
    "#vAR_df_IBR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Train Data from all Sources (Lease Amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "vAR_Collect_Train_Data_File_Lease_Amount() \n",
    "vAR_df_LA = vAR_df1 # +vAR_Collect_Train_Data_Hadoop_Unplanned_Charges()+vAR_Collect_Train_Data_SAPHANA_Unplanned_Charges()++vAR_Collect_Train_Data_Oracle_Unplanned_Charges()++vAR_Collect_Train_Data_MSSQL_Unplanned_Charges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vAR_Integrate_Train_Data_Lease_Amount():\n",
    "    vAR_Collect_Train_Data_File_Lease_Amount() \n",
    "    vAR_df_LA = vAR_df1 # +vAR_Collect_Train_Data_Hadoop_Unplanned_Charges()+vAR_Collect_Train_Data_SAPHANA_Unplanned_Charges()++vAR_Collect_Train_Data_Oracle_Unplanned_Charges()++vAR_Collect_Train_Data_MSSQL_Unplanned_Charges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "vAR_Integrate_Train_Data_Lease_Amount()\n",
    "#vAR_df_LA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Test Data from all Sources (Unplanned Charges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Train Data from all Sources (Lease Extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Train Data from all Sources (Extension Terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Train Data from all Sources (IBR %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Train Data from all Sources (Lease Amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
