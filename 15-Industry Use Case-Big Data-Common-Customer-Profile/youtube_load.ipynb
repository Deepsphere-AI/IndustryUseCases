{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chmod -R 777 '/home/dsailabusr1/PRAKASH/youtube_videos3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**********************************************************************************************************\n",
    "\n",
    "# File Name\t\t: \tyoutube_load.ipynb\n",
    "# Purpose\t\t\t:   Loading youtube data into bigquery table\n",
    "# Author\t\t\t:   DeepSphere.AI, Inc.\n",
    "# Date and Time \t: \t03/16/2021 10:30 hrs\n",
    "# Version\t\t\t: \t1.0 \n",
    "\n",
    "# /************************************************************************************************************\n",
    "\n",
    "\n",
    "def youtube_load():\n",
    "    from googleapiclient.discovery import build\n",
    "    from pytube import YouTube\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    import time\n",
    "    vAR_api_key = 'AIzaSyCcWatHXuBFpHaz4q4skndUsNVBzhBdilc'\n",
    "    vAR_topic = 'covid'\n",
    "    vAR_youtube = build('youtube', 'v3', developerKey=vAR_api_key)\n",
    "    vAR_request = vAR_youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            maxResults=5,\n",
    "            q=vAR_topic,\n",
    "            videoDuration=\"short\",type=\"video\",relevanceLanguage=\"en\"\n",
    "        )\n",
    "    vAR_response = vAR_request.execute()\n",
    "    # print(response)\n",
    "    vAR_videoIds = []\n",
    "    vAR_df = pd.DataFrame()\n",
    "    for lCount_idx in range(0,5):\n",
    "        videoId = vAR_response['items'][lCount_idx]['id']['videoId']\n",
    "        channelTitle = vAR_response['items'][lCount_idx]['snippet']['channelTitle']\n",
    "        videoTitle = vAR_response['items'][lCount_idx]['snippet']['title']\n",
    "        vAR_df.loc[lCount_idx,'youtube_url'] = 'https://www.youtube.com/watch?v='+videoId\n",
    "        vAR_df.loc[lCount_idx,'customer_id'] = channelTitle\n",
    "        vAR_df.loc[lCount_idx,'video_title'] = videoTitle\n",
    "        vAR_df.loc[lCount_idx,'location'] = vAR_response['regionCode']\n",
    "        vAR_df.loc[lCount_idx,'language'] = ''\n",
    "        vAR_df.loc[lCount_idx,'platform_source'] = 'youtube'\n",
    "        ts = time.time()\n",
    "        st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d')\n",
    "        vAR_df['created_time'] = st\n",
    "        #Below fields in data frame - we need to process and update in table\n",
    "        vAR_df.loc[lCount_idx,'text_content'] = ''\n",
    "        vAR_df.loc[lCount_idx,'summary_or_insights'] = ''\n",
    "        vAR_df.loc[lCount_idx,'video_labels'] = ''\n",
    "        vAR_videoIds.append(videoId)\n",
    "    \n",
    "    vAR_download_flag = copy_videos_gs(vAR_videoIds)\n",
    "    vAR_df['topic_or_hashtag'] = vAR_topic\n",
    "    vAR_np_array = get_gs_filename()\n",
    "    vAR_df['gs_file_name'] = vAR_np_array\n",
    "    vAR_insert_flag = bq_insert(vAR_df)\n",
    "    vAR_update_flag = video_text_bq_update()\n",
    "    return vAR_update_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bq_insert(df):\n",
    "    from google.cloud import bigquery\n",
    "    # Construct a BigQuery client object.\n",
    "    vAR_bq_client = bigquery.Client()\n",
    "    # TODO(developer): Set table_id to the ID of the table to create.\n",
    "    vAR_table_id = \"vast-verve-292018.ds_ai.ds_ai_youtube_data\"\n",
    "    vAR_job_config = bigquery.LoadJobConfig(\n",
    "        # Specify a (partial) schema. All columns are always written to the\n",
    "        # table. The schema is used to assist in data type definitions.\n",
    "        schema=[\n",
    "            # Specify the type of columns whose type cannot be auto-detected. For\n",
    "            # example the \"title\" column uses pandas dtype \"object\", so its\n",
    "            # data type is ambiguous.\n",
    "            bigquery.SchemaField(\"customer_id\", bigquery.enums.SqlTypeNames.STRING),\n",
    "            # Indexes are written if included in the schema by name.\n",
    "            bigquery.SchemaField(\"location\", bigquery.enums.SqlTypeNames.STRING),\n",
    "            bigquery.SchemaField(\"language\", bigquery.enums.SqlTypeNames.STRING),\n",
    "            bigquery.SchemaField(\"text_content\", bigquery.enums.SqlTypeNames.STRING),\n",
    "            bigquery.SchemaField(\"platform_source\", bigquery.enums.SqlTypeNames.STRING),\n",
    "            bigquery.SchemaField(\"summary_or_insights\", bigquery.enums.SqlTypeNames.STRING),\n",
    "            bigquery.SchemaField(\"video_title\", bigquery.enums.SqlTypeNames.STRING),\n",
    "            bigquery.SchemaField(\"video_labels\", bigquery.enums.SqlTypeNames.STRING),\n",
    "            bigquery.SchemaField(\"youtube_url\", bigquery.enums.SqlTypeNames.STRING),\n",
    "            bigquery.SchemaField(\"topic_or_hashtag\", bigquery.enums.SqlTypeNames.STRING),\n",
    "            bigquery.SchemaField(\"gs_file_name\", bigquery.enums.SqlTypeNames.STRING)\n",
    "            \n",
    "        ],\n",
    "        # Optionally, set the write disposition. BigQuery appends loaded rows\n",
    "        # to an existing table by default, but with WRITE_TRUNCATE write\n",
    "        # disposition it replaces the table with the loaded data.\n",
    "        write_disposition=\"WRITE_APPEND\",\n",
    "    )\n",
    "\n",
    "    vAR_job = vAR_bq_client.load_table_from_dataframe(\n",
    "        df, vAR_table_id, job_config=vAR_job_config\n",
    "    )  # Make an API request.\n",
    "    vAR_job.result()  # Wait for the job to complete.\n",
    "\n",
    "    vAR_table = vAR_bq_client.get_table(vAR_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {} and waiting for text_content to update\".format(\n",
    "            vAR_table.num_rows, len(vAR_table.schema), vAR_table_id\n",
    "        )\n",
    "    )\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_videos_gs(videoIds):\n",
    "    #Download all youtube videos into google storage\n",
    "    from pytube import YouTube\n",
    "    import subprocess\n",
    "    for lCount_id in videoIds:\n",
    "        YouTube(\"https://www.youtube.com/watch?v=\" + lCount_id).streams.first().download(\"/home/dsailabusr1/PRAKASH/youtube_videos3/\")\n",
    "    subprocess.call(['gsutil cp -r /home/dsailabusr1/PRAKASH/youtube_videos3/ gs://videoai_intelligence/VideoAI/'], shell=True)\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_text(filename):\n",
    "    import os\n",
    "    from google.cloud import videointelligence\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/dsailabusr1/PRAKASH/vast-verve-service-acc-key.json'\n",
    "    class audio_text:  \n",
    "        def __init__(self, transcript,confidence):  \n",
    "            self.transcript = transcript  \n",
    "            self.confidence = confidence\n",
    "    \"\"\"Transcribe speech from a video stored on GCS.\"\"\"\n",
    "\n",
    "    video_client = videointelligence.VideoIntelligenceServiceClient()\n",
    "    features = [videointelligence.Feature.SPEECH_TRANSCRIPTION]\n",
    "\n",
    "    config = videointelligence.SpeechTranscriptionConfig(\n",
    "        language_code=\"en-US\", enable_automatic_punctuation=True\n",
    "    )\n",
    "    video_context = videointelligence.VideoContext(speech_transcription_config=config)\n",
    "    # filename = 'This is iPhone 12 Pro â€” Apple'\n",
    "    path = 'gs://videoai_intelligence/VideoAI/youtube_videos3/'+filename+'.mp4'\n",
    "\n",
    "    operation = video_client.annotate_video(\n",
    "        request={\n",
    "            \"features\": features,\n",
    "            \"input_uri\": path,\n",
    "            \"video_context\": video_context\n",
    "        }\n",
    "    )\n",
    "#     print(\"\\nProcessing video for speech transcription for \",filename)\n",
    "    transcript = []\n",
    "    result = operation.result(timeout=6000)\n",
    "    # There is only one annotation_result since only\n",
    "    # one video is processed.\n",
    "    annotation_results = result.annotation_results[0]\n",
    "    for speech_transcription in annotation_results.speech_transcriptions:\n",
    "\n",
    "        # The number of alternatives for each transcription is limited by\n",
    "        # SpeechTranscriptionConfig.max_alternatives.\n",
    "        # Each alternative is a different possible transcription\n",
    "        # and has its own confidence score.\n",
    "        for alternative in speech_transcription.alternatives:\n",
    "\n",
    "            transcript.append(audio_text(\"Transcript: {}\".format(alternative.transcript),\n",
    "                                        \"Confidence: {}\\n\".format(alternative.confidence)))\n",
    "    text_content = ''\n",
    "    for i,trans in enumerate(transcript):\n",
    "        text_content +=trans.transcript\n",
    "    return text_content\n",
    "    # write_file(transcript,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_label(filename):\n",
    "    import os\n",
    "    from google.cloud import videointelligence\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/dsailabusr1/PRAKASH/vast-verve-service-acc-key.json'\n",
    "    class video_annotation:  \n",
    "        def __init__(self, vld,seg,conf):  \n",
    "            self.vld = vld  \n",
    "            self.seg = seg  \n",
    "            self.conf = conf\n",
    "    \"\"\" Detects labels given a GCS path. \"\"\"\n",
    "    try:\n",
    "        video_client = videointelligence.VideoIntelligenceServiceClient()\n",
    "        features = [videointelligence.Feature.LABEL_DETECTION]\n",
    "\n",
    "        mode = videointelligence.LabelDetectionMode.SHOT_AND_FRAME_MODE\n",
    "        config = videointelligence.LabelDetectionConfig(label_detection_mode=mode)\n",
    "        context = videointelligence.VideoContext(label_detection_config=config)\n",
    "    #     Please provide filename and google storage path\n",
    "        path = 'gs://videoai_intelligence/VideoAI/youtube_videos3/'+filename+'.mp4'\n",
    "        operation = video_client.annotate_video(\n",
    "            request={\"features\": features, \"input_uri\": path, \"video_context\": context}\n",
    "        )\n",
    "#         print(\"\\nProcessing video for label annotations: for file \",filename)\n",
    "\n",
    "        result = operation.result(timeout=1800)\n",
    "#         print(\"\\nFinished processing. for file \",filename)\n",
    "        segment_level_annotation = []\n",
    "        shot_level_annotation = []\n",
    "        frame_level_annotation = []\n",
    "        # Process video/segment level label annotations\n",
    "        segment_labels = result.annotation_results[0].segment_label_annotations\n",
    "        for i, segment_label in enumerate(segment_labels):\n",
    "#             for category_entity in segment_label.category_entities:\n",
    "#                 pass\n",
    "\n",
    "            for i, segment in enumerate(segment_label.segments):\n",
    "                start_time = (\n",
    "                    segment.segment.start_time_offset.seconds\n",
    "                    + segment.segment.start_time_offset.microseconds / 1e6\n",
    "                )\n",
    "                end_time = (\n",
    "                    segment.segment.end_time_offset.seconds\n",
    "                    + segment.segment.end_time_offset.microseconds / 1e6\n",
    "                )\n",
    "                positions = \"{}s to {}s\".format(start_time, end_time)\n",
    "                confidence = segment.confidence\n",
    "                segment_level_annotation.append(video_annotation(\"Video label description: {}\".format(segment_label.entity.description),\n",
    "                                                                \"\\tSegment {}: {}\".format(i, positions),\n",
    "                                                                \"\\tConfidence: {}\".format(confidence)))\n",
    "        # Process shot level label annotations\n",
    "        shot_labels = result.annotation_results[0].shot_label_annotations\n",
    "        for i, shot_label in enumerate(shot_labels):\n",
    "#             for category_entity in shot_label.category_entities:\n",
    "#                 pass\n",
    "\n",
    "            for i, shot in enumerate(shot_label.segments):\n",
    "                start_time = (\n",
    "                    shot.segment.start_time_offset.seconds\n",
    "                    + shot.segment.start_time_offset.microseconds / 1e6\n",
    "                )\n",
    "                end_time = (\n",
    "                    shot.segment.end_time_offset.seconds\n",
    "                    + shot.segment.end_time_offset.microseconds / 1e6\n",
    "                )\n",
    "                positions = \"{}s to {}s\".format(start_time, end_time)\n",
    "                confidence = shot.confidence\n",
    "                shot_level_annotation.append(video_annotation(\"Shot label description: {}\".format(shot_label.entity.description),\n",
    "                                                             \"\\tSegment {}: {}\".format(i, positions),\n",
    "                                                             \"\\tConfidence: {}\".format(confidence)))\n",
    "\n",
    "        # Process frame level label annotations\n",
    "        frame_labels = result.annotation_results[0].frame_label_annotations\n",
    "        for i, frame_label in enumerate(frame_labels):\n",
    "#             for category_entity in frame_label.category_entities:\n",
    "#                 pass\n",
    "\n",
    "            # Each frame_label_annotation has many frames,\n",
    "            # here we print information only about the first frame.\n",
    "            frame = frame_label.frames[0]\n",
    "            time_offset = frame.time_offset.seconds + frame.time_offset.microseconds / 1e6\n",
    "            frame_level_annotation.append(video_annotation(\"Frame label description: {}\".format(frame_label.entity.description),\n",
    "                                                          \"\\tFirst frame time offset: {}s\".format(time_offset),\n",
    "                                                          \"\\tFirst frame confidence: {}\".format(frame.confidence)))\n",
    "    #     write_file(segment_level_annotation,shot_level_annotation,frame_level_annotation,filename)\n",
    "        annotations = segment_level_annotation+shot_level_annotation+frame_level_annotation\n",
    "        label_content = ''\n",
    "        for item in annotations:\n",
    "            label_content += item.vld+item.seg+item.conf\n",
    "        return label_content\n",
    "    except BaseException as e:\n",
    "        print('error - ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackabuse.com/text-summarization-with-nltk-in-python/\n",
    "def summarize_text(article_text):\n",
    "    import nltk\n",
    "    import heapq\n",
    "    import re\n",
    "    # Removing Square Brackets and Extra Spaces\n",
    "    vAR_article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
    "    vAR_article_text = re.sub(r'\\s+', ' ', vAR_article_text)\n",
    "    # Removing special characters and digits\n",
    "    vAR_formatted_article_text = re.sub('[^a-zA-Z]', ' ', vAR_article_text )\n",
    "    vAR_formatted_article_text = re.sub(r'\\s+', ' ', vAR_formatted_article_text)\n",
    "    # Converting Text To Sentences\n",
    "    vAR_sentence_list = nltk.sent_tokenize(article_text)\n",
    "    vAR_stopwords = nltk.corpus.stopwords.words('english')\n",
    "    # Find Weighted Frequency of Occurrence\n",
    "    vAR_word_frequencies = {}\n",
    "    for word in nltk.word_tokenize(vAR_formatted_article_text):\n",
    "        if word not in vAR_stopwords:\n",
    "            if word not in vAR_word_frequencies.keys():\n",
    "                vAR_word_frequencies[word] = 1\n",
    "            else:\n",
    "                vAR_word_frequencies[word] += 1\n",
    "    if len(vAR_word_frequencies) >0:\n",
    "        maximum_frequncy = max(vAR_word_frequencies.values())\n",
    "    else:\n",
    "        maximum_frequncy = 1\n",
    "\n",
    "    for word in vAR_word_frequencies.keys():\n",
    "        vAR_word_frequencies[word] = (vAR_word_frequencies[word]/maximum_frequncy)\n",
    "    # Calculating Sentence Scores\n",
    "    vAR_sentence_scores = {}\n",
    "    for sent in vAR_sentence_list:\n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in vAR_word_frequencies.keys():\n",
    "                if len(sent.split(' ')) < 30:\n",
    "                    if sent not in vAR_sentence_scores.keys():\n",
    "                        vAR_sentence_scores[sent] = vAR_word_frequencies[word]\n",
    "                    else:\n",
    "                        vAR_sentence_scores[sent] += vAR_word_frequencies[word]\n",
    "    vAR_summary_sentences = heapq.nlargest(4, vAR_sentence_scores, key=vAR_sentence_scores.get)\n",
    "    vAR_summary = ' '.join(vAR_summary_sentences)\n",
    "    return vAR_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs://videoai_intelligence/VideoAI/youtube_videos2/This is iPhone 12 Pro â€” Apple.mp4\n",
    "# what if video_title same?\n",
    "def update_bq_tabel(text_content,label_content,summarize_content,filename,bq_client):\n",
    "    vAR_text_content = text_content.replace(\"'\",\"\")\n",
    "    vAR_label_content = label_content.replace(\"'\",\"\")\n",
    "    vAR_summarize_content = summarize_content.replace(\"'\",\"\")\n",
    "    vAR_query = \"UPDATE vast-verve-292018.ds_ai.ds_ai_youtube_data SET text_content =  '\"+vAR_text_content+\"',video_labels='\"+vAR_label_content+\"',summary_or_insights = '\"+vAR_summarize_content+\"' WHERE gs_file_name ='\"+filename+\"'\"\n",
    "    vAR_query_job = bq_client.query(vAR_query)  # API request\n",
    "    vAR_result = vAR_query_job.result()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video to Text and update big query table\n",
    "def video_text_bq_update():\n",
    "    from google.cloud import storage\n",
    "    vAR_client = storage.Client()\n",
    "    from google.cloud import bigquery\n",
    "    # Construct a BigQuery client object.\n",
    "    vAR_bq_client = bigquery.Client()\n",
    "    vAR_filename = []\n",
    "    for blob in vAR_client.list_blobs('videoai_intelligence',prefix='VideoAI/youtube_videos3'):\n",
    "    #     print(blob.name.replace('VideoAI/youtube_videos2/',''))\n",
    "        fname = blob.name.replace('VideoAI/youtube_videos3/','').replace('.mp4','')\n",
    "        if len(fname)>0:\n",
    "            vAR_filename.append(fname)\n",
    "    for file in vAR_filename:\n",
    "        print('Processing file - ',file)\n",
    "        vAR_text_content = video_to_text(file)\n",
    "        vAR_label_content = video_to_label(file)\n",
    "        vAR_summarize_content = summarize_text(vAR_text_content)\n",
    "        vAR_result = update_bq_tabel(vAR_text_content,vAR_label_content,vAR_summarize_content,file,vAR_bq_client)\n",
    "        if vAR_result:\n",
    "            print(file+' successfully updated with text_content')\n",
    "        else:\n",
    "            print('There is some problem in update table for file -',file)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gs_filename():\n",
    "    from google.cloud import storage\n",
    "    import numpy as np\n",
    "    vAR_client = storage.Client()\n",
    "    vAR_filename = []\n",
    "    for blob in vAR_client.list_blobs('videoai_intelligence',prefix='VideoAI/youtube_videos3'):\n",
    "    #     print(blob.name.replace('VideoAI/youtube_videos2/',''))\n",
    "        vAR_fname = blob.name.replace('VideoAI/youtube_videos3/','').replace('.mp4','')\n",
    "        if len(vAR_fname)>0:\n",
    "            vAR_filename.append(vAR_fname)\n",
    "    vAR_filenames = np.array(vAR_filename)\n",
    "    return vAR_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**********************************************************************************************************\n",
    "# Disclaimer.\n",
    "\n",
    "# We are providing this code block strictly for learning and researching, this is not a production ready code.\n",
    "# We have no liability on this particular code under any circumstances; users should\n",
    "# use this code on their own risk. All software,hardware and other products that are\n",
    "# referenced in these materials belong to the respective vendor who developed or who owns \n",
    "# this product.\n",
    "# /**********************************************************************************************************\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
