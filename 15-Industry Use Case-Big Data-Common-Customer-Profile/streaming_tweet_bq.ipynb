{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /**********************************************************************************************************\n",
    "\n",
    "# File Name\t\t: \tstreaming_tweet_bq.ipynb\n",
    "# Purpose\t\t\t:   Loading streaming tweets into bigquery table\n",
    "# Author\t\t\t:   DeepSphere.AI, Inc.\n",
    "# Date and Time \t: \t03/16/2021 10:30 hrs\n",
    "# Version\t\t\t: \t1.0 \n",
    "\n",
    "# /************************************************************************************************************\n",
    "\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "vAR_access_token = '1124283270-zjlHsFC9EkqvC1PAybE6NE4m43OPX8dZdM9GmnS'\n",
    "vAR_access_token_secret =  \"asJLhzYTI8dITcsqlSS4sgVE3ihN6b4TGVUoKHSTtAVJ3\"\n",
    "vAR_consumer_key =  \"S8PpgQWTXiWcmkdd5CTuUMYzT\"\n",
    "vAR_consumer_secret =  \"d85fJZ0t527YogNae17MqVIh452Zo8ZmQrnTPuz76j5p5Ps9Sj\"\n",
    "\n",
    "def upload_bq(rows_to_insert):\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    # Construct a BigQuery client object.\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # TODO(developer): Set table_id to the ID of table to append to.\n",
    "    table_id = \"vast-verve-292018.ds_ai.ds_ai_stream_tweets\"\n",
    "\n",
    "    errors = client.insert_rows_json(table_id, rows_to_insert)  # Make an API request.\n",
    "    if errors == []:\n",
    "        print(\"New rows have been added.\")\n",
    "    else:\n",
    "        print(\"Encountered errors while inserting rows: {}\".format(errors))\n",
    "\n",
    "def get_tweet_count():\n",
    "    from google.cloud import bigquery\n",
    "    import json\n",
    "    # Construct a BigQuery client object.\n",
    "    vAR_client = bigquery.Client()\n",
    "\n",
    "    # TODO(developer): Set table_id to the ID of the destination table.\n",
    "    vAR_sql = \"\"\"\n",
    "        SELECT count(1) as count FROM `vast-verve-292018.ds_ai.ds_ai_stream_tweets`\n",
    "    \"\"\"\n",
    "\n",
    "    # Start the query, passing in the extra configuration.\n",
    "    query_job = vAR_client.query(vAR_sql)  # Make an API request.\n",
    "    results =query_job.result()  # Wait for the job to complete.\n",
    "    for res in results:\n",
    "        count = res.count\n",
    "    return count\n",
    "\n",
    "class twitterAuth():\n",
    "\n",
    "    def authenticateTwitterApp(self):\n",
    "        vAR_auth = OAuthHandler(vAR_consumer_key, vAR_consumer_secret)\n",
    "        vAR_auth.set_access_token(vAR_access_token, vAR_access_token_secret)\n",
    "        return vAR_auth\n",
    "class TwitterStreamer():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.twitterAuth = twitterAuth()\n",
    "        \n",
    "\n",
    "    def stream_tweets(self):\n",
    "        while True:\n",
    "            vAR_listener = ListenerTS() \n",
    "            vAR_auth = self.twitterAuth.authenticateTwitterApp()\n",
    "            rName_stream = Stream(vAR_auth, vAR_listener)\n",
    "            rName_stream.filter(track=[\"covid\"], stall_warnings=True, languages= [\"en\"])\n",
    "\n",
    "class ListenerTS(StreamListener):\n",
    "\n",
    "    def on_data(self, raw_data):\n",
    "            tweet_count = get_tweet_count()\n",
    "            if tweet_count>100:\n",
    "                raise Exception(\"We got more than 100+ tweets\")\n",
    "            vAR_dtime = datetime.now()\n",
    "            print(f'[{vAR_dtime.hour}:{vAR_dtime.minute}:{vAR_dtime.second}] sending tweet')\n",
    "            upload_bq([{\"tweet\":raw_data}])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Loading Streaming tweets into Bigquery Table\n",
    "        rName_TS = TwitterStreamer()\n",
    "        rName_TS.stream_tweets()\n",
    "    except:\n",
    "        !gsutil rm -r gs://videoai_intelligence/VideoAI/youtube_videos3\n",
    "        !find /home/dsailabusr1/PRAKASH/youtube_videos3 -type f -delete\n",
    "        print('Already processed youtube files deleted automatically')\n",
    "        # Twitter Data Load into Bigquery Table\n",
    "        %run /home/dsailabusr1/PRAKASH/DE-Framework/DE-Framework-Impl/Framework/twitter_load.ipynb\n",
    "        vAR_twitter_load_flag = twitter_load()\n",
    "        print('twitter_load flag - ',vAR_twitter_load_flag)\n",
    "        \n",
    "        # Youtube data load into Bigquery Table\n",
    "        %run /home/dsailabusr1/PRAKASH/DE-Framework/DE-Framework-Impl/Framework/youtube_load.ipynb\n",
    "        vAR_youtube_load_flag = youtube_load()\n",
    "        print('youtube_load flag - ',vAR_youtube_load_flag)\n",
    "        \n",
    "        # Image data load into Bigquery Table\n",
    "        %run /home/dsailabusr1/PRAKASH/DE-Framework/DE-Framework-Impl/Framework/image_load.ipynb\n",
    "        vAR_image_load_flag = image_load()\n",
    "        print('image_load flag - ',vAR_image_load_flag)\n",
    "        \n",
    "        # Integrating all above table into single Bigquery Table\n",
    "        %run /home/dsailabusr1/PRAKASH/DE-Framework/DE-Framework-Impl/Framework/data_integration.ipynb\n",
    "        vAR_integrate_load_flag = data_integrate()\n",
    "        print('integrated_data_load flag - ',vAR_integrate_load_flag)\n",
    "        \n",
    "        # Applying Kmeans clustering Model to above integrated data\n",
    "        %run /home/dsailabusr1/PRAKASH/DE-Framework/DE-Framework-Impl/Framework/bigqueryML.ipynb\n",
    "        vAR_model_flag = kmeans_model()\n",
    "        print('model_prediction flag - ',vAR_model_flag)\n",
    "        \n",
    "        # Customizing model output\n",
    "        %run /home/dsailabusr1/PRAKASH/DE-Framework/DE-Framework-Impl/Framework/customer_group.ipynb\n",
    "        vAR_model_op_flag = bq_insert_bqml()\n",
    "        print('model_op_customized flag - ',vAR_model_op_flag)\n",
    "        \n",
    "# /**********************************************************************************************************\n",
    "# Disclaimer.\n",
    "\n",
    "# We are providing this code block strictly for learning and researching, this is not a production ready code.\n",
    "# We have no liability on this particular code under any circumstances; users should\n",
    "# use this code on their own risk. All software,hardware and other products that are\n",
    "# referenced in these materials belong to the respective vendor who developed or who owns \n",
    "# this product.\n",
    "# /**********************************************************************************************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
