{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\durga\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29_0_1_20170116205643042.jpg.chip.jpg [1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                                 | 1/100 [00:00<00:22,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29_0_1_20170116210509902.jpg.chip.jpg [1, 0]\n",
      "29_0_1_20170116214326195.jpg.chip.jpg [1, 0]\n",
      "29_0_1_20170117012800357.jpg.chip.jpg [1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▎                                                                              | 4/100 [00:00<00:16,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29_0_1_20170117015458481.jpg.chip.jpg [1, 0]\n",
      "29_1_0_20170112235530689.jpg.chip.jpg [0, 1]\n",
      "29_1_0_20170112487607250.jpg.chip.jpg [0, 1]\n",
      "29_1_0_20170113000327017.jpg.chip.jpg [0, 1]\n",
      "29_1_0_20170113000811442.jpg.chip.jpg [0, 1]\n",
      "29_1_0_20170113012607249.jpg.chip.jpg [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                         | 10/100 [00:00<00:11,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_0_1_20170113133122016.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113133238257.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113133323665.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113133612273.jpg.chip.jpg [1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▎                                                                     | 14/100 [00:00<00:08, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_0_1_20170113133719624.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113134006616.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113134204447.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113134217498.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113141654362.jpg.chip.jpg [1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▍                                                                 | 19/100 [00:00<00:06, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_0_1_20170113141818644.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113141822196.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113141846612.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113151342687.jpg.chip.jpg [1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▋                                                              | 23/100 [00:00<00:04, 16.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_0_1_20170113152824163.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113155013364.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113173357107.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113190459754.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113190501769.jpg.chip.jpg [1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▋                                                          | 28/100 [00:00<00:03, 20.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_0_1_20170113195438285.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170113195630213.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170114033434587.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170116002938608.jpg.chip.jpg [1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▉                                                       | 32/100 [00:01<00:02, 23.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_0_1_20170116010614771.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170116010647849.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170116010659651.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170116011020977.jpg.chip.jpg [1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▏                                                   | 36/100 [00:01<00:02, 26.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_0_1_20170116024856991.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170116213438554.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170116213558934.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170116214526846.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170116214710372.jpg.chip.jpg [1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▏                                               | 41/100 [00:01<00:01, 29.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_0_1_20170117094442927.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170117120438367.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170117123820956.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170117123837646.jpg.chip.jpg [1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▍                                            | 45/100 [00:01<00:01, 31.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_0_1_20170117123839619.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170117123902427.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170117123914245.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170117123915360.jpg.chip.jpg [1, 0]\n",
      "30_0_1_20170117130022204.jpg.chip.jpg [1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▌                                        | 50/100 [00:01<00:01, 34.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_0_1_20170117202910591.jpg.chip.jpg [1, 0]\n",
      "30_0_2_20170116164401454.jpg.chip.jpg [1, 0]\n",
      "30_0_2_20170116164436658.jpg.chip.jpg [1, 0]\n",
      "30_0_2_20170116170852517.jpg.chip.jpg [1, 0]\n",
      "30_0_2_20170116172532435.jpg.chip.jpg [1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████▌                                    | 55/100 [00:01<00:01, 32.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_1_2_20170104020133916.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170104020408339.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170104020413511.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170104020459348.jpg.chip.jpg [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████▊                                 | 59/100 [00:01<00:01, 31.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_1_2_20170104020950540.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170104021318733.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170104022925822.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170104164904841.jpg.chip.jpg [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████████                              | 63/100 [00:01<00:01, 28.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_1_2_20170104192931704.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170105002521620.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170105161432042.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170105170141222.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116161338805.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116161420356.jpg.chip.jpg [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████▉                         | 69/100 [00:02<00:01, 30.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_1_2_20170116161740145.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116162002429.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116162625578.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116162634192.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116163458646.jpg.chip.jpg [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▉                     | 74/100 [00:02<00:00, 30.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_1_2_20170116163642750.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116163932623.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116164729972.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116164737724.jpg.chip.jpg [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████████████████████████████████████▏                 | 78/100 [00:02<00:00, 32.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_1_2_20170116165139757.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116170703197.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116171019788.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116174642075.jpg.chip.jpg [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|██████████████████████████████████████████████████████████████████▍              | 82/100 [00:02<00:00, 34.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_1_2_20170116184611730.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116191207397.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116191220057.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116191317558.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116191902270.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116192241195.jpg.chip.jpg [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|███████████████████████████████████████████████████████████████████████▎         | 88/100 [00:02<00:00, 38.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_1_2_20170116192245601.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116192313635.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116192334382.jpg.chip.jpg [0, 1]\n",
      "30_1_2_20170116192341274.jpg.chip.jpg [0, 1]\n",
      "30_1_3_20170104223046816.jpg.chip.jpg [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████████████▎     | 93/100 [00:02<00:00, 40.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_1_3_20170104223318647.jpg.chip.jpg [0, 1]\n",
      "30_1_3_20170104231521681.jpg.chip.jpg [0, 1]\n",
      "30_1_3_20170104231945705.jpg.chip.jpg [0, 1]\n",
      "30_1_3_20170104232147226.jpg.chip.jpg [0, 1]\n",
      "30_1_3_20170104232927250.jpg.chip.jpg [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|███████████████████████████████████████████████████████████████████████████████▍ | 98/100 [00:02<00:00, 33.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_1_3_20170104235219219.jpg.chip.jpg [0, 1]\n",
      "30_1_3_20170104235527578.jpg.chip.jpg [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 33.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\durga\\Anaconda3\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\Users\\durga\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\core.py:239: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\durga\\Anaconda3\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\durga\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "#********************************************************************************\n",
    "\n",
    "## Step 1: INI File Configuration\n",
    "\n",
    "#********************************************************************************\n",
    "\n",
    "# Importing the configparser library\n",
    "\n",
    "import configparser\n",
    "\n",
    "# Importing the configparser library\n",
    "\n",
    "import os\n",
    "\n",
    "#********************************************************************************\n",
    "\n",
    "## Some configuration files are known to include settings without values, \n",
    "\n",
    "## The allow_no_value parameter to the constructor can be used to indicate that such values should be accepted:\n",
    "\n",
    "vAR_Config = configparser.ConfigParser(allow_no_value=True)\n",
    "\n",
    "#********************************************************************************\n",
    "\n",
    "## Reading the .INI File  and its sections through the set environment variable\n",
    "\n",
    "vAR_INI_FILE_PATH = os.getenv('GENDER_DETECTION_INI_FILE_DL')\n",
    "#print(vAR_INI_FILE_PATH)\n",
    "\n",
    "vAR_Config.read(vAR_INI_FILE_PATH)\n",
    "\n",
    "vAR_Data = vAR_Config.sections()\n",
    "\n",
    "vAR_Config.sections()\n",
    "\n",
    "#********************************************************************************\n",
    "\n",
    "## Reading the Training Data Path\n",
    "\n",
    "vAR_TRAIN_DIR = vAR_Config['FILE PATH']['TRAINING_DATA']\n",
    "#print(vAR_TRAIN_DIR)\n",
    "\n",
    "## Reading the Test Data Path\n",
    "\n",
    "vAR_TEST_DIR = vAR_Config['FILE PATH']['TEST_DATA']\n",
    "#print(vAR_Test_Data)\n",
    "\n",
    "## Reading the Model Outcome Path\n",
    "\n",
    "vAR_Outcomedatapath = vAR_Config['FILE PATH']['MODEL_OUTCOME']\n",
    "#print(vAR_Model_Outcome)\n",
    "\n",
    "## Setting the Images Pixel Size\n",
    "\n",
    "vAR_IMG_SIZE = vAR_Config['FILE PATH']['IMG_SIZE']\n",
    "vAR_IMG_SIZE = int(vAR_IMG_SIZE)\n",
    "#print(vAR_IMG_SIZE)\n",
    "\n",
    "## Setting the Learning Rate for the NN Model\n",
    "\n",
    "vAR_LR = vAR_Config['FILE PATH']['LEARNING_RATE']\n",
    "vAR_LR = float(vAR_LR)\n",
    "#print(vAR_LR)\n",
    "\n",
    "\n",
    "vAR_SRC = vAR_Config['FILE PATH']['SRC']\n",
    "\n",
    "vAR_DST = vAR_Config['FILE PATH']['DST']\n",
    "\n",
    "vAR_PATH = vAR_Config['FILE PATH']['PATH']\n",
    "\n",
    "vAR_MODEL_NAME=\"Malevsfemale-{}-{}.model\".format(vAR_LR,'6conv_basic_video')\n",
    "\n",
    "#********************************************************************************\n",
    "    \n",
    "## Step 2: Importing the Required Libraries\n",
    "\n",
    "#********************************************************************************\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as vAR_pd\n",
    "\n",
    "import numpy as vAR_np\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from random import shuffle\n",
    "\n",
    "#from IPython.display import display\n",
    "\n",
    "import PIL\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tflearn\n",
    "\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "\n",
    "#********************************************************************************\n",
    "    \n",
    "## Step 3: Importing the Training Data\n",
    "\n",
    "#********************************************************************************\n",
    "\n",
    "def label_img(img):\n",
    "    \n",
    "    vAR_gender=img.split('_')[1]\n",
    "    \n",
    "    if vAR_gender == '0' : return [1,0]    # Assigning 1,o to male\n",
    "    \n",
    "    elif vAR_gender== '1' : return [0,1]   # ASSIGNING [0,1] to female\n",
    "    \n",
    "def create_train_data():\n",
    "    \n",
    "    vAR_training_data=[]\n",
    "    \n",
    "    for img in tqdm(os.listdir(vAR_TRAIN_DIR)):\n",
    "    \n",
    "        vAR_label=label_img(img)\n",
    "        \n",
    "        print(img,vAR_label)\n",
    "        \n",
    "        vAR_path=os.path.join(vAR_TRAIN_DIR, img)\n",
    "        \n",
    "        vAR_img = cv2.imread(vAR_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        #print(vAR_img)\n",
    "        \n",
    "        #vAR_resizedimg.empty()\n",
    "        \n",
    "        vAR_resizedimg=cv2.resize(vAR_img, (vAR_IMG_SIZE, vAR_IMG_SIZE))\n",
    "        \n",
    "        #print(vAR_resizedimg)\n",
    "        \n",
    "        vAR_training_data.append([vAR_np.array(vAR_resizedimg),vAR_np.array(vAR_label)])\n",
    "    \n",
    "    shuffle(vAR_training_data)\n",
    "    \n",
    "    #vAR_np.save('vAR_training_data.npy', vAR_training_data)\n",
    "    \n",
    "    #print(os.listdir(vAR_TRAIN_DIR))\n",
    "    \n",
    "    #print(img)\n",
    "    \n",
    "    #print(vAR_label)\n",
    "    \n",
    "    #print(label_img)\n",
    "    \n",
    "    return vAR_training_data      \n",
    "\n",
    "create_train_data()\n",
    "\n",
    "\n",
    "#********************************************************************************\n",
    "    \n",
    "## Step 4: Importing the CNN Model\n",
    "\n",
    "#********************************************************************************\n",
    "\n",
    "import tflearn\n",
    "\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "convnet = input_data(shape=[None, vAR_IMG_SIZE, vAR_IMG_SIZE, 1], name='input')\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='sigmoid')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=vAR_LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='/tmp')\n",
    "\n",
    "##########################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 59  | total loss: 0.69311 | time: 0.214s\n",
      "| Adam | epoch: 030 | loss: 0.69311 - acc: 0.5151 -- iter: 064/100\n",
      "Training Step: 60  | total loss: 0.69310 | time: 0.425s\n",
      "| Adam | epoch: 030 | loss: 0.69310 - acc: 0.5167 -- iter: 100/100\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#********************************************************************************\n",
    "\n",
    "## Step 5: Training the Model\n",
    "\n",
    "#********************************************************************************\n",
    "\n",
    "import os\n",
    "\n",
    "if os.path.exists('{}.meta'.format(vAR_MODEL_NAME)):\n",
    "    \n",
    "    model.load(vAR_MODEL_NAME)\n",
    "    \n",
    "    print('model loaded!')\n",
    "\n",
    "vAR_train_data=create_train_data()\n",
    "\n",
    "vAR_train=vAR_train_data[:]\n",
    "\n",
    "print (vAR_train)\n",
    "\n",
    "vAR_test=vAR_train_data[:10]\n",
    "\n",
    "vAR_Length=len(vAR_test)\n",
    "\n",
    "#print (vAR_Length)\n",
    "\n",
    "vAR_X = vAR_np.array([i[0] for i in vAR_train], dtype=vAR_np.float64).reshape(-1, vAR_IMG_SIZE, vAR_IMG_SIZE,1)\n",
    "\n",
    "#print(vAR_X)\n",
    "\n",
    "vAR_Y = vAR_np.array([i[1] for i in vAR_train], dtype=vAR_np.float64)\n",
    "\n",
    "vAR_test_X = vAR_np.array([i[0] for i in vAR_test], dtype=vAR_np.float64).reshape(-1, vAR_IMG_SIZE, vAR_IMG_SIZE,1)\n",
    "\n",
    "vAR_test_Y = vAR_np.array([i[1] for i in vAR_test], dtype=vAR_np.float64)\n",
    "\n",
    "##TRAINING THE MODEL, \n",
    " #validation_set=({'input': vAR_test_X}, {'targets': vAR_test_Y}),,snapshot_step=500\n",
    "\n",
    "model.fit({'input': vAR_X}, {'targets': vAR_Y}, validation_set=None, n_epoch=30, show_metric=True, run_id=vAR_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1992.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1088.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50103134 0.49900547]\n",
      "20170116205643042.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116210509902.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116214326195.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170117012800357.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170117015458481.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170112235530689.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170112487607250.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113000327017.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113000811442.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113012607249.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113133122016.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113133238257.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113133323665.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113133612273.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113133719624.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113134006616.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113134204447.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113134217498.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113141654362.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113141818644.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113141822196.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113141846612.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113151342687.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113152824163.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113155013364.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113173357107.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113190459754.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113190501769.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113195438285.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170113195630213.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170114033434587.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116002938608.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116010614771.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116010647849.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116010659651.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116011020977.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116024856991.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116213438554.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116213558934.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116214526846.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116214710372.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170117094442927.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170117120438367.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170117123820956.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170117123837646.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170117123839619.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170117123902427.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170117123914245.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170117123915360.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170117130022204.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170117202910591.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116164401454.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116164436658.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116170852517.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116172532435.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104020133916.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104020408339.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104020413511.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104020459348.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104020950540.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104021318733.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104022925822.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104164904841.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104192931704.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170105002521620.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170105161432042.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170105170141222.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116161338805.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116161420356.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116161740145.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116162002429.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116162625578.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116162634192.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116163458646.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116163642750.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116163932623.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116164729972.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116164737724.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116165139757.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116170703197.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116171019788.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116174642075.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116184611730.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116191207397.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116191220057.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116191317558.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116191902270.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116192241195.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116192245601.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116192313635.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116192334382.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170116192341274.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104223046816.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104223318647.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104231521681.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104231945705.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104232147226.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104232927250.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104235219219.jpg.chip.jpg Male\n",
      "[0.50103134 0.49900547]\n",
      "20170104235527578.jpg.chip.jpg Male\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/AI/Gender Detection/DL/TEST DATA\\29_0_1_20170116205643042.jpg\n",
      "C:/AI/Gender Detection/DL/TEST DATA\\29_0_1_20170116210509902.jpg\n",
      "C:/AI/Gender Detection/DL/TEST DATA\\29_0_1_20170116214326195.jpg\n",
      "C:/AI/Gender Detection/DL/TEST DATA\\29_0_1_20170117012800357.jpg\n",
      "C:/AI/Gender Detection/DL/TEST DATA\\29_0_1_20170117015458481.jpg\n",
      "C:/AI/Gender Detection/DL/TEST DATA\\29_1_0_20170112235530689.jpg\n",
      "C:/AI/Gender Detection/DL/TEST DATA\\29_1_0_20170113000327017.jpg\n",
      "C:/AI/Gender Detection/DL/TEST DATA\\29_1_0_20170113000811442.jpg\n",
      "C:/AI/Gender Detection/DL/TEST DATA\\29_1_0_20170113012607249.jpg\n",
      "C:/AI/Gender Detection/DL/TEST DATA\\29_1_1_20170104192718648.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 664.32it/s]\n"
     ]
    }
   ],
   "source": [
    "#********************************************************************************\n",
    "    \n",
    "## Step 6: Import the Test Data\n",
    "\n",
    "#********************************************************************************\n",
    "\n",
    "def process_test_data():\n",
    "    \n",
    "    vAR_testing_data=[]\n",
    "    \n",
    "    for img in tqdm(os.listdir(vAR_TRAIN_DIR)):\n",
    "        \n",
    "        path=os.path.join(vAR_TRAIN_DIR,img)\n",
    "        \n",
    "        vAR_img_num=img.split('_')[-1]\n",
    "        \n",
    "        vAR_img=cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (vAR_IMG_SIZE, vAR_IMG_SIZE))\n",
    "        \n",
    "        vAR_testing_data.append([vAR_np.array(vAR_img), vAR_img_num])\n",
    "        \n",
    "    #vAR_np.save('vAR_test_data.npy', vAR_testing_data)\n",
    "    \n",
    "    return vAR_testing_data\n",
    "\n",
    "vAR_test_data = process_test_data()\n",
    "\n",
    "#vAR_test_data\n",
    "\n",
    "\n",
    "#********************************************************************************\n",
    "    \n",
    "## Step 7: Gender Detection (Model Prediction)\n",
    "\n",
    "#********************************************************************************\n",
    "\n",
    "vAR_model_out = model.predict(vAR_test_X)\n",
    "\n",
    "def process_test_data():\n",
    "    \n",
    "    vAR_testing_data=[]\n",
    "    \n",
    "    for img in tqdm(os.listdir(vAR_TRAIN_DIR)):\n",
    "        \n",
    "        path=os.path.join(vAR_TRAIN_DIR,img)\n",
    "        \n",
    "        vAR_img_num=img.split('_')[-1]\n",
    "        \n",
    "        vAR_img=cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (vAR_IMG_SIZE, vAR_IMG_SIZE))\n",
    "        \n",
    "        vAR_testing_data.append([vAR_np.array(vAR_img), vAR_img_num])\n",
    "        \n",
    "    #vAR_np.save('vAR_test_data.npy', vAR_testing_data)\n",
    "    \n",
    "    return vAR_testing_data\n",
    "\n",
    "vAR_test_data = process_test_data()\n",
    "\n",
    "#vAR_test_data\n",
    "\n",
    "for num, data in enumerate(vAR_test_data[:]):\n",
    "    \n",
    "    vAR_img_num=data[1]\n",
    "    \n",
    "    vAR_img_data=data[0]\n",
    "    \n",
    "    data=vAR_img_data.reshape(vAR_IMG_SIZE,vAR_IMG_SIZE,1)\n",
    "    \n",
    "    vAR_model_out=model.predict([data])[0]\n",
    "    \n",
    "    print(vAR_model_out)\n",
    "    \n",
    "    if vAR_np.argmax(vAR_model_out)==0 : \n",
    "        \n",
    "        vAR_str_label=\"Male\"\n",
    "        \n",
    "        print(vAR_img_num,vAR_str_label)\n",
    "    \n",
    "    else: \n",
    "        \n",
    "        vAR_str_label='Female'\n",
    "        \n",
    "        print(vAR_img_num,vAR_str_label)\n",
    "        \n",
    "\n",
    "import shutil\n",
    "\n",
    "src= vAR_SRC\n",
    "\n",
    "dst = vAR_DST\n",
    "\n",
    "shutil.copytree(src=vAR_SRC, dst=vAR_DST)\n",
    "\n",
    "#********************************************************************************\n",
    "    \n",
    "## Step 8: Write the Model Outcome to a file\n",
    "\n",
    "#********************************************************************************\n",
    "\n",
    "i = 0\n",
    "\n",
    "path = vAR_PATH\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    \n",
    "    my_dest = vAR_str_label + str(i) + \".jpg\"\n",
    "    \n",
    "    my_source =path + filename\n",
    "    \n",
    "    my_dest =path + my_dest\n",
    "    \n",
    "    os.rename(my_source, my_dest)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "\n",
    "images = []\n",
    "    \n",
    "for img in tqdm(os.listdir(vAR_TEST_DIR)):\n",
    "    \n",
    "    path = os.path.join(vAR_TEST_DIR,img)\n",
    "    \n",
    "    img_num = path\n",
    "    \n",
    "    if img is not None:\n",
    "        \n",
    "        images.append(img_num)\n",
    "        \n",
    "        print(img_num)\n",
    "\n",
    "\n",
    "#********************************************************************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
