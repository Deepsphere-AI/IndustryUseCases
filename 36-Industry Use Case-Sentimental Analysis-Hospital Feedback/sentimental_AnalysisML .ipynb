{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d9de644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "#import contractions\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9065cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"reviews.csv\", engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b558b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tag(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a074247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove accented characters\n",
    "def strip_accents(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b78a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters\n",
    "def strip_special_characters(text):\n",
    "    text = re.sub('[^a-zA-z0-9\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a57224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTION_MAP = {\"ain't\": \"is not\",\"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\",\n",
    "                   \"'cause\": \"because\", \"dr\" : \"doctor\",\n",
    "                   \"could've\": \"could have\",\n",
    "                   \"couldn't\": \"could not\",\n",
    "                   \"couldn't've\": \"could not have\",\n",
    "                   \"didn't\": \"did not\",\n",
    "                   \"doesn't\": \"does not\",\n",
    "                   \"don't\": \"do not\",\n",
    "                   \"hadn't\": \"had not\",\n",
    "                   \"hadn't've\": \"had not have\",\n",
    "                   \"hasn't\": \"has not\",\n",
    "                   \"haven't\": \"have not\",\n",
    "                   \"he'd\": \"he would\",\n",
    "                   \"he'd've\": \"he would have\",\n",
    "                   \"he'll\": \"he will\",\n",
    "                   \"he'll've\": \"he will have\",\n",
    "                   \"he's\": \"he is\",\n",
    "                   \"how'd\": \"how did\",\n",
    "                   \"how'd'y\": \"how do you\",\n",
    "                   \"how'll\": \"how will\",\n",
    "                   \"how's\": \"how is\",\n",
    "                   \"I'd\": \"I would\",\n",
    "                   \"I'd've\": \"I would have\",\n",
    "                   \"I'll\": \"I will\",\n",
    "                   \"I'll've\": \"I will have\",\n",
    "                   \"I'm\": \"I am\",\n",
    "                   \"I've\": \"I have\",\n",
    "                   \"i'd\": \"i would\",\n",
    "                   \"i'd've\": \"i would have\",\n",
    "                   \"i'll\": \"i will\",\n",
    "                   \"i'll've\": \"i will have\",\n",
    "                   \"i'm\": \"i am\",\n",
    "                   \"i've\": \"i have\",\n",
    "                   \"isn't\": \"is not\",\n",
    "                   \"it'd\": \"it would\",\n",
    "                   \"it'd've\": \"it would have\",\n",
    "                   \"it'll\": \"it will\",\n",
    "                   \"it'll've\": \"it will have\",\n",
    "                   \"it's\": \"it is\",\n",
    "                   \"let's\": \"let us\",\n",
    "                   \"ma'am\": \"madam\",\n",
    "                   \"mayn't\": \"may not\",\n",
    "                   \"might've\": \"might have\",\n",
    "                   \"mightn't\": \"might not\",\n",
    "                   \"mightn't've\": \"might not have\",\n",
    "                   \"must've\": \"must have\",\n",
    "                   \"mustn't\": \"must not\",\n",
    "                   \"mustn't've\": \"must not have\",\n",
    "                   \"needn't\": \"need not\",\n",
    "                   \"needn't've\": \"need not have\",\n",
    "                   \"o'clock\": \"of the clock\",\n",
    "                   \"oughtn't\": \"ought not\",\n",
    "                   \"oughtn't've\": \"ought not have\",\n",
    "                   \"shan't\": \"shall not\",\n",
    "                   \"sha'n't\": \"shall not\",\n",
    "                   \"shan't've\": \"shall not have\",\n",
    "                   \"she'd\": \"she would\",\n",
    "                   \"she'd've\": \"she would have\",\n",
    "                   \"she'll\": \"she will\",\n",
    "                   \"she'll've\": \"she will have\",\n",
    "                   \"she's\": \"she is\",\n",
    "                   \"should've\": \"should have\",\n",
    "                   \"shouldn't\": \"should not\",\n",
    "                   \"shouldn't've\": \"should not have\",\n",
    "                   \"so've\": \"so have\",\n",
    "                   \"so's\": \"so as\",\n",
    "                   \"that'd\": \"that would\",\n",
    "                   \"that'd've\": \"that would have\",\n",
    "                   \"that's\": \"that is\",\n",
    "                   \"there'd\": \"there would\",\n",
    "                   \"there'd've\": \"there would have\",\n",
    "                   \"there's\": \"there is\",\n",
    "                   \"they'd\": \"they would\",\n",
    "                   \"they'd've\": \"they would have\",\n",
    "                   \"they'll\": \"they will\",\n",
    "                   \"they'll've\": \"they will have\",\n",
    "                   \"they're\": \"they are\",\n",
    "                   \"they've\": \"they have\",\"to've\": \"to have\",\n",
    "                   \"wasn't\": \"was not\",\n",
    "                   \"we'd\": \"we would\",\n",
    "                   \"we'd've\": \"we would have\",\n",
    "                   \"we'll\": \"we will\",\n",
    "                   \"we'll've\": \"we will have\",\n",
    "                   \"we're\": \"we are\",\n",
    "                   \"we've\": \"we have\",\n",
    "                   \"weren't\": \"were not\",\n",
    "                   \"what'll\": \"what will\",\n",
    "                   \"what'll've\": \"what will have\",\n",
    "                   \"what're\": \"what are\",\n",
    "                   \"what's\": \"what is\",\n",
    "                   \"what've\": \"what have\",\n",
    "                   \"when's\": \"when is\",\n",
    "                   \"when've\": \"when have\",\n",
    "                   \"where'd\": \"where did\",\n",
    "                   \"where's\": \"where is\",\n",
    "                   \"where've\": \"where have\",\n",
    "                   \"who'll\": \"who will\",\n",
    "                   \"who'll've\": \"who will have\",\n",
    "                   \"who's\": \"who is\",\n",
    "                   \"who've\": \"who have\",\n",
    "                   \"why's\": \"why is\",\n",
    "                   \"why've\": \"why have\",\n",
    "                   \"will've\": \"will have\",\n",
    "                   \"won't\": \"will not\",\n",
    "                   \"won't've\": \"will not have\",\n",
    "                   \"would've\": \"would have\",\n",
    "                   \"wouldn't\": \"would not\",\n",
    "                   \"wouldn't've\": \"would not have\",\n",
    "                   \"y'all\": \"you all\",\n",
    "                   \"y'all'd\": \"you all would\",\n",
    "                   \"y'all'd've\": \"you all would have\",\n",
    "                   \"y'all're\": \"you all are\",\n",
    "                   \"y'all've\": \"you all have\",\n",
    "                   \"you'd\": \"you would\",\n",
    "                   \"you'd've\": \"you would have\",\n",
    "                   \"you'll\": \"you will\",\n",
    "                   \"you'll've\": \"you will have\",\n",
    "                   \"you're\": \"you are\",\n",
    "                   \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14d475d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2338a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos tagging\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5c0a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(text):\n",
    "    #remove html tags\n",
    "    text = strip_html_tag(text)\n",
    "\n",
    "    #convert accented characters\n",
    "    text = strip_accents(text)\n",
    "  \n",
    "    #expand contractions\n",
    "    text = expand_contractions(text)\n",
    "\n",
    "    #lower case \n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove special characters\n",
    "    text = strip_special_characters(text)\n",
    "\n",
    "    # tokenize text and remove puncutation\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "\n",
    "    # remove stop words\n",
    "    stopword_list = set(stopwords.words('english'))\n",
    "    stopword_list.remove('not')\n",
    "    stopword_list.remove('no')\n",
    "\n",
    "  \n",
    "    text = [x for x in text if x not in stopword_list]\n",
    " \n",
    "    # pos tag text\n",
    "    pos_tags = pos_tag([word for word in text if word])\n",
    "\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "\n",
    "    text = \" \".join(text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f647b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"review_clean\"] = data[\"Reviews\"].apply(lambda x: clean_review(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfc227f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data[\"review_clean\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49763fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent(data):\n",
    "    if data['Rating'] < 3:\n",
    "        val = 'neg' #0\n",
    "        \n",
    "    elif data['Rating'] >= 3:\n",
    "        val = 'pos' #1\n",
    "    else:\n",
    "        val = 'neutral'\n",
    "    return val\n",
    "data['sentiment'] = data.apply(sent, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fee8bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f05f7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f32bc442",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a59962fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data['review_clean'].tolist()\n",
    "labels = y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d1fff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Bag of Words model\n",
    "cv = CountVectorizer()\n",
    "reviews_cv = cv.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9793a07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_nb.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a pickle file for the CountVectorizer model\n",
    "joblib.dump(cv, \"cv.pkl\")\n",
    "\n",
    "\n",
    "# Model Building\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    reviews_cv, labels, test_size=0.20, random_state=0)\n",
    "\n",
    "# Fitting Naive Bayes to the Training set\n",
    "classifier = MultinomialNB(alpha=0.2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Creating a pickle file for the Multinomial Naive Bayes model\n",
    "joblib.dump(classifier, \"model_nb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b64e139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_lr.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic regression\n",
    "lr_classifier =  LogisticRegression(max_iter=1000)\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "joblib.dump(lr_classifier, \"model_lr.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb96c15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_svc.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_classifier = LinearSVC()\n",
    "svc_classifier.fit(X_train,y_train)\n",
    "joblib.dump(svc_classifier,\"model_svc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d10e2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb:  0.9777992277992278\n",
      "lr:  0.9927606177606177\n",
      "svc:  0.9927606177606177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "training_accuracy_mnb = accuracy_score(y_train, classifier.predict(X_train))\n",
    "training_accuracy_lr = accuracy_score(y_train, lr_classifier.predict(X_train))\n",
    "training_accuracy_svc = accuracy_score(y_train, svc_classifier.predict(X_train))\n",
    "print(\"mnb: \", training_accuracy_mnb)\n",
    "print(\"lr: \", training_accuracy_lr)\n",
    "print(\"svc: \", training_accuracy_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d6ed15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_prediction = classifier.predict(X_test)\n",
    "lr_prediction = lr_classifier.predict(X_test)\n",
    "svc_prediction =svc_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "267b4dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(open('model_nb.pkl', 'rb'))\n",
    "cv = joblib.load(open('cv.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbb02bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb:  0.8783783783783784\n",
      "lr:  0.8474903474903475\n",
      "Svc:  0.8436293436293436\n"
     ]
    }
   ],
   "source": [
    "testing_accuracy_mnb = accuracy_score(y_test, mnb_prediction)\n",
    "lr_test_accuracy = accuracy_score(y_test, lr_prediction)\n",
    "svc_test_accuracy = accuracy_score(y_test, svc_prediction)\n",
    "print(\"mnb: \", testing_accuracy_mnb)\n",
    "print(\"lr: \", lr_test_accuracy)\n",
    "print(\"Svc: \", svc_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8489df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       166\n",
      "           1       0.91      0.91      0.91       352\n",
      "\n",
      "    accuracy                           0.88       518\n",
      "   macro avg       0.86      0.86      0.86       518\n",
      "weighted avg       0.88      0.88      0.88       518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, mnb_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e5278dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['Negative', 'Positive']\n",
    "def get_prediction(review):\n",
    "    # Preprocessing\n",
    "    #print(type(review))\n",
    "    review_data = clean_review(review)\n",
    "    #print(\"clean: \",review_data)\n",
    "    vectorizer = cv.transform([review_data]).toarray()\n",
    "    prediction = model.predict(vectorizer)\n",
    "    pred_labels = LABELS[int(prediction[0])]\n",
    "    \n",
    "    \n",
    "    print('REVIEW: ', review, '\\nPREDICTION: ', prediction , '\\nLabel: ',pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c7be54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW:   Doctors are fine. Billing/Insurance staff is unprofessional and incompetent to a level that I have never experienced at any other medical office. Aside from lacking basic decency and common sense, I had to file a formal complaint as the staff violated numerous HIPAA laws. This place is a mess.  \n",
      "PREDICTION:  [0] \n",
      "Label:  Negative\n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"\"\" Doctors are fine. Billing/Insurance staff is unprofessional and incompetent to a level that I have never experienced at any other medical office. Aside from lacking basic decency and common sense, I had to file a formal complaint as the staff violated numerous HIPAA laws. This place is a mess. \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096fe89e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
