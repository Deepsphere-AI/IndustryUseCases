{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "printable-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet allennlp==0.9.0\n",
    "# !pip install --quiet spacy==2.1.9\n",
    "# !pip install --quiet https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adapted-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar â€“xvzf en_core_web_sm-2.1.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "close-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "classical-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo-constituency-parser-2018.03.14.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "buried-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "proper-salvation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your label namespace was 'pos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old woman was sitting under a tree and sipping coffee\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"The old woman was sitting under a tree and sipping coffee.\"\n",
    "test_sentence = test_sentence.rstrip('?:!.,;')\n",
    "print (test_sentence)\n",
    "parser_output = predictor.predict(sentence=test_sentence)\n",
    "# print (parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "healthy-poultry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (DT The) (JJ old) (NN woman)) (VP (VBD was) (VP (VP (VBG sitting) (PP (IN under) (NP (DT a) (NN tree)))) (CC and) (VP (VBG sipping) (NP (NN coffee))))))\n"
     ]
    }
   ],
   "source": [
    "tree_string = parser_output[\"trees\"]\n",
    "print (tree_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "later-mortgage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (DT The) (JJ old) (NN woman))\n",
      "  (VP\n",
      "    (VBD was)\n",
      "    (VP\n",
      "      (VP (VBG sitting) (PP (IN under) (NP (DT a) (NN tree))))\n",
      "      (CC and)\n",
      "      (VP (VBG sipping) (NP (NN coffee))))))\n",
      "                            S                                          \n",
      "      ______________________|________                                   \n",
      "     |                               VP                                \n",
      "     |          _____________________|_______                           \n",
      "     |         |                             VP                        \n",
      "     |         |                  ___________|________________          \n",
      "     |         |                 VP               |           |        \n",
      "     |         |      ___________|___             |           |         \n",
      "     |         |     |               PP           |           VP       \n",
      "     |         |     |       ________|___         |      _____|____     \n",
      "     NP        |     |      |            NP       |     |          NP  \n",
      "  ___|____     |     |      |         ___|___     |     |          |    \n",
      " DT  JJ   NN  VBD   VBG     IN       DT      NN   CC   VBG         NN  \n",
      " |   |    |    |     |      |        |       |    |     |          |    \n",
      "The old woman was sitting under      a      tree and sipping     coffee\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "from nltk.tree import Tree\n",
    "\n",
    "tree = Tree.fromstring(tree_string)\n",
    "print (tree)\n",
    "print (tree.pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "promising-script",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence  The old woman was sitting under a tree and sipping coffee\n",
      "last_nounphrase  (NP (NN coffee))\n",
      "last_verbphrase  (VP (VBG sipping) (NP (NN coffee)))\n",
      "\n",
      " \n",
      "last_nounphrase  coffee\n",
      "last_verbphrase  sipping coffee\n"
     ]
    }
   ],
   "source": [
    "# split at right most nounphrase or verbphrase\n",
    "\n",
    "def get_flattened(t):\n",
    "    sent_str_final = None\n",
    "    if t is not None:\n",
    "        sent_str = [\" \".join(x.leaves()) for x in list(t)]\n",
    "        sent_str_final = [\" \".join(sent_str)]\n",
    "        sent_str_final = sent_str_final[0]\n",
    "    return sent_str_final\n",
    "\n",
    "def get_right_most_VP_or_NP(parse_tree,last_NP = None,last_VP = None):\n",
    "    if len(parse_tree.leaves()) == 1:\n",
    "        return last_NP,last_VP\n",
    "    last_subtree = parse_tree[-1]\n",
    "    if last_subtree.label() == \"NP\":\n",
    "        last_NP = last_subtree\n",
    "    elif last_subtree.label() == \"VP\":\n",
    "        last_VP = last_subtree\n",
    "    \n",
    "    return get_right_most_VP_or_NP(last_subtree,last_NP,last_VP)\n",
    "\n",
    "\n",
    "last_nounphrase, last_verbphrase =  get_right_most_VP_or_NP(tree)\n",
    "last_nounphrase_flattened = get_flattened(last_nounphrase)\n",
    "last_verbphrase_flattened = get_flattened(last_verbphrase)\n",
    "\n",
    "print (\"Original Sentence \",test_sentence)\n",
    "print (\"last_nounphrase \",last_nounphrase )\n",
    "print (\"last_verbphrase \",last_verbphrase)\n",
    "print (\"\\n \")\n",
    "print (\"last_nounphrase \",last_nounphrase_flattened )\n",
    "print (\"last_verbphrase \",last_verbphrase_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "auburn-logic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending phrase:  sipping coffee\n",
      "Original sentence :  The old woman was sitting under a tree and sipping coffee\n",
      "Original sentence after splitting at ending phrase:  The old woman was sitting under a tree and\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# sub_string - sipping coffee\n",
    "# main_string - The old woman was sitting under a tree and sipping coffee\n",
    "# compare like below\n",
    "# Theoldwomanwassittingunderatreeandsippingcoffee  || sippingcoffee\n",
    "# oldwomanwassittingunderatreeandsippingcoffee || sippingcoffee\n",
    "# womanwassittingunderatreeandsippingcoffee || sippingcoffee\n",
    "# ...............\n",
    "# andsippingcoffee || sippingcoffee\n",
    "# sippingcoffee || sippingcoffee\n",
    "def get_termination_portion(main_string, sub_string):\n",
    "    combined_sub_string = sub_string.replace(\" \", \"\")\n",
    "    main_string_list = main_string.split()\n",
    "    last_index = len(main_string_list)\n",
    "    for i in range(last_index):\n",
    "        check_string_list = main_string_list[i:]\n",
    "        check_string = \"\".join(check_string_list)\n",
    "        check_string = check_string.replace(\" \", \"\")\n",
    "        if check_string == combined_sub_string:\n",
    "            return \" \".join(main_string_list[:i])\n",
    "\n",
    "    return None\n",
    "\n",
    "longest_phrase_to_use = max(last_nounphrase_flattened, last_verbphrase_flattened)\n",
    "print (\"Ending phrase: \", longest_phrase_to_use)\n",
    "\n",
    "longest_phrase_to_use = re.sub(r\"-LRB- \", \"(\", longest_phrase_to_use)\n",
    "longest_phrase_to_use = re.sub(r\" -RRB-\", \")\", longest_phrase_to_use)\n",
    "\n",
    "\n",
    "split_sentence = get_termination_portion(test_sentence, longest_phrase_to_use)\n",
    "print (\"Original sentence : \",test_sentence)\n",
    "print (\"Original sentence after splitting at ending phrase: \",split_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-innocent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rational-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda uninstall h5py\n",
    "# !pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "operational-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# GPT2tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
    "# GPT2model = TFGPT2LMHeadModel.from_pretrained(\"distilgpt2\",pad_token_id=GPT2tokenizer.eos_token_id)\n",
    "GPT2tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "GPT2model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\",pad_token_id=GPT2tokenizer.eos_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "animal-patch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 464 1468 2415  373 5586  739  257 5509  290]], shape=(1, 9), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "partial_sentence = \"The old woman was sitting under a tree and\"\n",
    "input_ids = GPT2tokenizer.encode(partial_sentence,return_tensors='tf')\n",
    "print (input_ids)\n",
    "maximum_length = len(partial_sentence.split())+40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "early-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate top_k sampling and top_p sampling with only from 90% most likely words\n",
    "sample_outputs = GPT2model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=maximum_length, \n",
    "    top_p=0.80, # 0.85 \n",
    "    top_k=60,   #30\n",
    "    repetition_penalty  = 10.0,\n",
    "    num_return_sequences=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "presidential-background",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  The old woman was sitting under a tree and looking at the trees, thinking of her own life.\n",
      "1 :  The old woman was sitting under a tree and he took her hand.\n",
      "2 :  The old woman was sitting under a tree and couldn't get her hair down.\n",
      "3 :  The old woman was sitting under a tree and she said, \"I'm not sure if you're talking to the young lady in your room or her parents.\n",
      "4 :  The old woman was sitting under a tree and looking at me.\n",
      "5 :  The old woman was sitting under a tree and had her hand on his shoulder.\n",
      "6 :  The old woman was sitting under a tree and holding her hand, but she turned around to look at him.\n",
      "7 :  The old woman was sitting under a tree and standing over it, her face covered in dust.\n",
      "8 :  The old woman was sitting under a tree and she had just started to cry when the voice of her aunt came out.\n",
      "9 :  The old woman was sitting under a tree and her arms were folded around herself, so she leaned back in the chair.\n",
      "10 :  The old woman was sitting under a tree and listening to the breeze.\n",
      "11 :  The old woman was sitting under a tree and looking out of the window.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import tokenize\n",
    "generated_sentences=[]\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    decoded_sentence = GPT2tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "    # final_sentence = decoded_sentence\n",
    "    final_sentence = tokenize.sent_tokenize(decoded_sentence)[0]\n",
    "    generated_sentences.append(final_sentence)\n",
    "    print (i,\": \",final_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-climate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single sentence true or false\n",
    "#Multiple sentence true or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/nlp-how-tokenizing-text-sentence-words-works/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-dietary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
