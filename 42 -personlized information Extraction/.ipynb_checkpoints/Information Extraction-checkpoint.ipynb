{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84275e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nameparser\n",
      "  Using cached nameparser-1.1.1-py2.py3-none-any.whl (24 kB)\n",
      "Installing collected packages: nameparser\n",
      "Successfully installed nameparser-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nameparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11bb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words(‘english’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2255ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = ‘ ‘.join([i for i in document.split() if i not in stop])\n",
    "sentences = nltk.sent_tokenize(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [nltk.word_tokenize(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [nltk.pos_tag(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d03519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_addresses(string):\n",
    "    r = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    return r.findall(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_names(document):\n",
    "    names = []\n",
    "    sentences = ie_preprocess(document)\n",
    "    for tagged_sentence in sentences:\n",
    "        for chunk in nltk.ne_chunk(tagged_sentence):\n",
    "            if type(chunk) == nltk.tree.Tree:\n",
    "                if chunk.label() == 'PERSON':\n",
    "                    names.append(' '.join([c[0] for c in chunk]))\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a13dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_preprocess(document):\n",
    "    document = ' '.join([i for i in document.split() if i not in stop])\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ce0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    numbers = extract_phone_numbers(string)\n",
    "    emails = extract_email_addresses(string)\n",
    "    names = extract_names(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe4e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f830937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd962cfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age is 32\n",
      "phone number is 9678967686\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sentence = 'Steve Jones, Age: 32, 9678967686'\n",
    "print(\"Age is \"+ re.findall(r\"\\b\\d{2}\\b\", sentence)[0])\n",
    "print(\"phone number is \"+ re.findall(r\"\\b\\d{10}\\b\", sentence)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce58b2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Francois R. Velde', 'Richard Branson', 'Economist Paul Krugman', 'Nick Colas']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nameparser.parser import HumanName\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "person_list = []\n",
    "person_names=person_list\n",
    "def get_human_names(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    pos = nltk.pos_tag(tokens)\n",
    "    sentt = nltk.ne_chunk(pos, binary = False)\n",
    "\n",
    "    person = []\n",
    "    name = \"\"\n",
    "    for subtree in sentt.subtrees(filter=lambda t: t.label() == 'PERSON'):\n",
    "        for leaf in subtree.leaves():\n",
    "            person.append(leaf[0])\n",
    "        if len(person) > 1: #avoid grabbing lone surnames\n",
    "            for part in person:\n",
    "                name += part + ' '\n",
    "            if name[:-1] not in person_list:\n",
    "                person_list.append(name[:-1])\n",
    "            name = ''\n",
    "        person = []\n",
    "#     print (person_list)\n",
    "\n",
    "text = \"\"\"\n",
    "\n",
    "Some economists have responded positively to Bitcoin, including \n",
    "Francois R. Velde, senior economist of the Federal Reserve in Chicago \n",
    "who described it as \"an elegant solution to the problem of creating a \n",
    "digital currency.\" In November 2013 Richard Branson announced that \n",
    "Virgin Galactic would accept Bitcoin as payment, saying that he had invested \n",
    "in Bitcoin and found it \"fascinating how a whole new global currency \n",
    "has been created\", encouraging others to also invest in Bitcoin.\n",
    "Other economists commenting on Bitcoin have been critical. \n",
    "Economist Paul Krugman has suggested that the structure of the currency \n",
    "incentivizes hoarding and that its value derives from the expectation that \n",
    "others will accept it as payment. Economist Larry Summers has expressed \n",
    "a \"wait and see\" attitude when it comes to Bitcoin. Nick Colas, a market \n",
    "strategist for ConvergEx Group, has remarked on the effect of increasing \n",
    "use of Bitcoin and its restricted supply, noting, \"When incremental \n",
    "adoption meets relatively fixed supply, it should be no surprise that \n",
    "prices go up. And that’s exactly what is happening to BTC prices.\"\n",
    "\"\"\"\n",
    "\n",
    "names = get_human_names(text)\n",
    "for person in person_list:\n",
    "    person_split = person.split(\" \")\n",
    "    for name in person_split:\n",
    "        if wordnet.synsets(name):\n",
    "            if(name in person):\n",
    "                person_names.remove(person)\n",
    "                break\n",
    "\n",
    "print(person_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "with open('Text.txt') as f:\n",
    "    string = f.readlines()\n",
    "    \n",
    "class InformationExtraction:    \n",
    "    def extract_phone_numbers(self,string):\n",
    "        s1 = [s+'.' for s in str(string).split('.') if 'phone number' in s]\n",
    "        r = re.compile(r'(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4})')\n",
    "        phone_numbers = r.findall(str(string))\n",
    "        print(\"Phone Number-\"+ str(s1))\n",
    "        return [re.sub(r'\\D', '', number) for number in phone_numbers]\n",
    "\n",
    "    def extract_email_addresses(self,string):\n",
    "        r = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "        return r.findall(str(string))\n",
    "\n",
    "    def extract_adhar_number(self,string):\n",
    "        r = re.compile(r'^[2-9]{1}[0-9]{3}\\\\s[0-9]{4}\\\\s[0-9]{4}$')\n",
    "        return r.findall(str(string))\n",
    "\n",
    "    def extract_age(self,string):\n",
    "    #     r = re.compile(r'/(am\\s)(\\d{1,2})/')\n",
    "        r = re.compile(r'\\d+(?=[\\s]?years)')\n",
    "        return r.findall(str(string))\n",
    "    \n",
    "    def extract_date_of_birth(self,string):\n",
    "        s1 = [s+'.' for s in str(string).split('.') if 'birth' in s]\n",
    "#         r = re.compile(r'(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4})')\n",
    "#         phone_numbers = r.findall(str(string))\n",
    "        print(\"DOB is-\"+ str(s1))\n",
    "#         return [re.sub(r'\\D', '', number) for number in phone_numbers]\n",
    "    \n",
    "    def extract_license(self,string):\n",
    "#         r = re.compile(r'^(([A-Z]{2}[0-9]{2})( )|([A-Z]{2}-[0-9]{2}))((19|20)[0-9][0-9])[0-9]{7}$')\n",
    "#         return r.findall(str(string))\n",
    "\n",
    "        s1 = [s+'.' for s in str(string).split('.') if 'license' in s]\n",
    "        print(\"Driving License is-\"+ str(s1))\n",
    "        \n",
    "    def extract_credit_card(self,string):\n",
    "        s1 = [s+'.' for s in str(string).split('.') if 'credit card' in s]\n",
    "        print(\"credit card number is-\"+ str(s1))\n",
    "        \n",
    "    def ie_preprocess(self,string):\n",
    "        string = ' '.join([i for i in str(string).split() if i not in stop])\n",
    "        sentences = nltk.sent_tokenize(string)\n",
    "        sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "        sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "        return sentences\n",
    "\n",
    "    def extract_names(self,document):\n",
    "\n",
    "        names = []\n",
    "        sentences = self.ie_preprocess(string)\n",
    "        for tagged_sentence in sentences:\n",
    "            for chunk in nltk.ne_chunk(tagged_sentence):\n",
    "                if type(chunk) == nltk.tree.Tree:\n",
    "                    if chunk.label() == 'PERSON':\n",
    "                        names.append(' '.join([c[0] for c in chunk]))\n",
    "        return names\n",
    "    \n",
    "def main(): \n",
    "    obj = InformationExtraction()\n",
    "    numbers =obj.extract_phone_numbers(string)\n",
    "#     print(numbers)\n",
    "#     emails = obj.extract_email_addresses(string)\n",
    "#     print(emails)\n",
    "    names = obj.extract_names(string)\n",
    "    print(\"Full Name -\" + str(names))\n",
    "    age = obj.extract_age(string)\n",
    "#     print(age)\n",
    "    obj.extract_date_of_birth(string)\n",
    "    obj.extract_license(string)\n",
    "    obj.extract_credit_card(string)\n",
    "#     adharno = obj.extract_adhar_number(string)\n",
    "#     print(adharno)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
